{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf1_dense_network.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf1_dense_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr0VcfeYoEBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "de6c6e95-e1ce-4138-8040-777e0427b213"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "1.15.2\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 1.0.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 1.15.2\n",
            "tensorflow.python.keras.api._v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmlVLkuooEBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b705db4c-29d4-4610-e703-241a717c13be"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
        "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
        "\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28) (5000,)\n",
            "(55000, 28, 28) (55000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbPer5kQoEBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21e44ee2-13bc-4163-f737-66122bfd87e0"
      },
      "source": [
        "print(np.max(x_train), np.min(x_train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssTNhlxioEBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = (x - u) / std\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# x_train: [None, 28, 28] -> [None, 784]\n",
        "x_train_scaled = scaler.fit_transform(\n",
        "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_valid_scaled = scaler.transform(\n",
        "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_test_scaled = scaler.transform(\n",
        "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5LseAVfoEBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba690b26-227b-454f-9053-33aacf211ed9"
      },
      "source": [
        "print(np.max(x_train_scaled), np.min(x_train_scaled))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0231433 -0.8105136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WXBBFSZoEBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "d44b8650-88e2-4672-a558-81a0cf012494"
      },
      "source": [
        "hidden_units = [100, 100] # 2层 每层100的单元的全连接网络\n",
        "class_num = 10 #10类\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28 * 28]) #x用来存放数据也就是图像。placeholder也就占位符，占位符是网络中的一部分\n",
        "#数据通过占位符输入进网络，网络再通过占位符呢读取到数据之后呢，他可能会做两件事情\n",
        "#第一件就是： 给这些数据做预测\n",
        "#第二件就是： 利用这些数据去做训练\n",
        "#x 用来存放图像，28*28是图像的大小，None是batch_size的大小。表示batch_size可以是任意值\n",
        "#y shape也是none,他需要跟x做对应。\n",
        "#placeholder呢在2.0里呢已经被取消了，这是为什么呢\n",
        "#在tensorflow1.0里面呢，需要先构建图，再去运行这个图。所以在构建图的过程中是看不到数据的。\n",
        "#所以无法把数据传进来，所以需要一个占位符顶替数据的位置。在tensorflow2.0里面则不需要这样了\n",
        "\n",
        "y = tf.placeholder(tf.int64, [None]) #y用来存放label。\n",
        "\n",
        "#定义一个临时变量\n",
        "input_for_next_layer = x\n",
        "for hidden_unit in hidden_units:\n",
        "    #构建一个新的层次，在tensorflow1.0里面构建全连接层的API是tf.layers.dense，他在2.0已经被移到keras.layers.dense里面去了\n",
        "    #参数有三个： 第一个输入，hidden_unit数目，激活函数\n",
        "    input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                           hidden_unit,\n",
        "                                           activation=tf.nn.relu)\n",
        "#输出层 也是一个全连接层，输入就是input_for_next_layer， unit数目就是class_num，他没有激活函数\n",
        "logits = tf.layers.dense(input_for_next_layer, class_num)\n",
        "# last_hidden_output * W(logits) -> softmax -> prob\n",
        "# 1. logit -> softmax -> prob\n",
        "# 2. labels -> one_hot\n",
        "# 3. calculate cross entropy\n",
        "# 有了yhat以后就可以和y去计算损失函数了.这里使用softmax_cross_entropy来计算，他的API就是 tf.losses.sparse_softmax_cross_entropy\n",
        "# 他有两个参数，logits就是最后一层隐含层乘以一个矩阵得到的一个直接的输出这个就是logits。 这个logits输出再经过一个softmax以后呢，就变成了概率。\n",
        "# 也就是在概率输出前的叫logits\n",
        "# 在这个函数中呢，他会首先给logits计算概率\n",
        "# 还会给labels计算one_hot编码，有了one-hot编码和概率以后，他就可以去计算交叉熵cross entropy\n",
        "# 这是这个函数所做的事情，\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels = y, logits = logits)\n",
        "# get accuracy.\n",
        "prediction = (tf.argmaxlogits, 1) #他的proiction就是logits最大的那个值的索引 https://blog.csdn.net/UESTC_C2_403/article/details/72232807\n",
        "correct_prediction = tf.equal(prediction, y) #01的一个向量，0是错误，1是正确\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64)) #取平均就好，取平均前，变成float64,不然最后就是0\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss) #train_op用来训练网络的，这个train_op运行一次，网络就训练一次\n",
        "#tf.train.AdamOptimizer(1e-3).minimize(loss)返回一个train_op. train_op也是tf1.0的一个特性，在tf1.0里面要先构建图\n",
        "#然后在去训练，train_op也是为了这个逻辑而存在的，在构建完图以后呢，train_op也被构建为图的一部分，我只要运行这个train_op\n",
        "#就相当于把这个图训练了一遍"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-a0dd67f10b9f>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6PqU3fNoEBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7ab48bd0-560e-4fe8-d4fd-16eee22e1b3f"
      },
      "source": [
        "print(x)\n",
        "print(logits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
            "Tensor(\"dense_2/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axcWK1L-oEBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "122fd7e8-fd25-486c-8234-39cec7d6891e"
      },
      "source": [
        "# session\n",
        "# 接下来运行这个图\n",
        "# session是客户端程序和c++ 运行时的一个连接\n",
        "# 什么是c++运行时，我们在构建好图以后，图就是一个c++运行时，因为tensorflow的图是c++实现的\n",
        "# 客户端一般指的是我们的python程序\n",
        "# session就是这些客户端和c++运行时的一个连接\n",
        "# 打开一个session以后，就可以在客户端里运行c++运行时了\n",
        "init = tf.global_variables_initializer()\n",
        "batch_size = 20\n",
        "epochs = 10\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "valid_steps = x_valid.shape[0] // batch_size\n",
        "\n",
        "#验证集的返回结果\n",
        "def eval_with_sess(sess,  accuracy, images, labels, batch_size):\n",
        "    eval_steps = images.shape[0] // batch_size\n",
        "    eval_accuracies = []\n",
        "    for step in range(eval_steps):\n",
        "        batch_data = images[step * batch_size : (step+1) * batch_size]\n",
        "        batch_label = labels[step * batch_size : (step+1) * batch_size]\n",
        "        accuracy_val = sess.run(accuracy, #我不去调用train_op,我只需要accuracy就可以了\n",
        "                                feed_dict = {\n",
        "                                    x: batch_data,\n",
        "                                    y: batch_label\n",
        "                                })\n",
        "        eval_accuracies.append(accuracy_val)\n",
        "    return np.mean(eval_accuracies)\n",
        "\n",
        "#很类似keras的fit函数，遍历训练集，然后在测试集验证下\n",
        "with tf.Session() as sess: #打开session\n",
        "    sess.run(init) #运行初始化\n",
        "    for epoch in range(epochs):\n",
        "        for step in range(train_steps_per_epoch):\n",
        "            batch_data = x_train_scaled[ #取出来对应的data\n",
        "                step * batch_size : (step+1) * batch_size]\n",
        "            batch_label = y_train[  #取出来label\n",
        "                step * batch_size : (step+1) * batch_size]\n",
        "            #不关心train_op的值，只是关心loss_val和accuracy_val\n",
        "            loss_val, accuracy_val, _ = sess.run( #使用sess.run调用train_op\n",
        "                [loss, accuracy, train_op],\n",
        "                feed_dict = {\n",
        "                    x: batch_data,\n",
        "                    y: batch_label\n",
        "                })\n",
        "            print('\\r[Train] epoch: %d, step: %d, loss: %3.5f, accuracy: %2.2f' % (\n",
        "                epoch, step, loss_val, accuracy_val), end=\"\") #打印中间训练过程\n",
        "        #每个epoch结束以后呢，需要在验证集上进行一下验证\n",
        "        valid_accuracy = eval_with_sess(sess,  accuracy,\n",
        "                                        x_valid_scaled, y_valid,\n",
        "                                        batch_size)\n",
        "        print(\"\\t[Valid] acc: %2.2f\" % (valid_accuracy))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] epoch: 0, step: 2749, loss: 0.19854, accuracy: 0.90\t[Valid] acc: 0.86\n",
            "[Train] epoch: 1, step: 2749, loss: 0.17359, accuracy: 0.90\t[Valid] acc: 0.87\n",
            "[Train] epoch: 2, step: 2749, loss: 0.12006, accuracy: 0.95\t[Valid] acc: 0.88\n",
            "[Train] epoch: 3, step: 2749, loss: 0.14087, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 4, step: 2749, loss: 0.19757, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 5, step: 2749, loss: 0.19841, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 6, step: 2749, loss: 0.14377, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 7, step: 2749, loss: 0.15756, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 8, step: 2749, loss: 0.11145, accuracy: 0.95\t[Valid] acc: 0.87\n",
            "[Train] epoch: 9, step: 2749, loss: 0.12014, accuracy: 0.95\t[Valid] acc: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGscaQceoEBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}