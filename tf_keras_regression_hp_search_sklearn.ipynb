{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf_keras_regression-hp-search-sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf_keras_regression_hp_search_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1FTZu85yMRh",
        "colab_type": "code",
        "outputId": "f0a63760-136c-4cf9-816d-3902af8447d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 0.25.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 2.1.0\n",
            "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcIEkxZXyMRn",
        "colab_type": "code",
        "outputId": "762786a9-35ab-4c9a-cea5-698bccc3a9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo0Baty1yMRr",
        "colab_type": "code",
        "outputId": "1969057b-98f3-4588-e1c8-a1700c8675cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_VK6U5yMRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO7750CWyMRw",
        "colab_type": "code",
        "outputId": "ad1e24bc-0b48-468d-e4f7-b864a6bfaf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "# 我们使用sklearn里面的 RandomizedSearchCV 来实现我们超参数的随机化搜索.需要实现下面3步\n",
        "# 1. 转化为sklearn的model。我们要使用这个函数呢，因为这个是sklearn里面的一个函数，\n",
        "#   所以呢，我们要先把我们的tf-kerasmodel转成sklean的model.通过KerasRegressor或者KerasClassifier实现转换\n",
        "# 2. 定义参数集合。转成skleanr的model以后我们就可以定义参数集合，使用RandomizedSearchCV去搜索参数\n",
        "# 3. 搜索参数。\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "def build_model(hidden_layers = 1, # 中间层的层数\n",
        "                layer_size = 30, #默认就是30，表示如果没有参数传进来的时候的默认值就是30，如果传进来其他值得话 就会把这个数覆盖\n",
        "                learning_rate = 3e-3):\n",
        "    model = keras.models.Sequential()\n",
        "    # 为什么我们要把第一个add跟for循环里面的add分开呢，因为呢第一层需要设置一个输入shape，而其他的隐含层不需要，因为其他的隐含层的输入都是上面隐藏层的输出\n",
        "    # 所以说他可以自己推导出来，只有第一个不知道输入的shape是多大的\n",
        "    model.add(keras.layers.Dense(layer_size, activation='relu',input_shape=x_train.shape[1:]))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(layer_size, activation = 'relu'))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    # 因为learning_rate是可变的，所以这里optimizer是自定义的\n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "    model.compile(loss = 'mse', optimizer = optimizer)\n",
        "    return model\n",
        "\n",
        "#1.  首先使用build_model，定义一个keras model，然后调用函数KerasClassifier或者KerasRegressor把keras model 封装成一个 sklearn 支持的 model\n",
        "sklearn_model = KerasRegressor( # KerasClassifier 和 KerasRegressor\n",
        "    build_fn = build_model) # 把我们定义的keras model 转成sklean model，然后这个KerasRegressor函数呢，接受的参数是一个bulid_fn\n",
        "                 # bulid_fn呢，也就是一个函数，这个函数返回的是一个搭建好的tf keras model\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
        "\n",
        "#2. 因为这已经是一个独立的sklearn的函数了，所以我们依然可以调用fit函数，因为在sklearn里他也支持这个fit函数，并记录返回值到history里面\n",
        "history = sklearn_model.fit(x_train_scaled, y_train,\n",
        "                            epochs = 10,\n",
        "                            validation_data = (x_valid_scaled, y_valid),\n",
        "                            callbacks = callbacks) #然后把callback也传进来"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 1.6086 - val_loss: 0.8110\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.7213 - val_loss: 0.7229\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.6495 - val_loss: 0.6674\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5995 - val_loss: 0.6149\n",
            "Epoch 5/10\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5599 - val_loss: 0.5816\n",
            "Epoch 6/10\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5292 - val_loss: 0.5503\n",
            "Epoch 7/10\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5048 - val_loss: 0.5230\n",
            "Epoch 8/10\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4851 - val_loss: 0.5067\n",
            "Epoch 9/10\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4735 - val_loss: 0.4904\n",
            "Epoch 10/10\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4650 - val_loss: 0.4822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lanaiinvyMRz",
        "colab_type": "code",
        "outputId": "86e03c15-4ecd-4541-ae36-6296c64988a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0, 1)\n",
        "    plt.show()\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAEzCAYAAADkYKBTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKy1cWPyMR2",
        "colab_type": "code",
        "outputId": "c746c40c-429a-4072-ed90-bccc632b4b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "# f(x) = 1/(x*log(b/a)) a <= x <= b x在(a,b)之间每个值呢 取值的概率就是这样算出来的\n",
        "\n",
        "param_distribution = {\n",
        "    \"hidden_layers\":[1, 2, 3, 4], #隐层个数\n",
        "    \"layer_size\": np.arange(1, 100), #1,2,3 一直到00\n",
        "    \"learning_rate\": reciprocal(1e-4, 1e-2), \n",
        "                # learngingrate我希望他的取值是一个连续取值，他是在一个连续空间内进行取值，我定义他的最大值最小值就可以啦\n",
        "                # 因此呢 我使用一个分布来生成learningrate使用一个分布生成连续的值，这个分布呢，是reciprocal的一个分布\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#初始化这个对象 \n",
        "random_search_cv = RandomizedSearchCV(sklearn_model, # 之前定义的sklearn形式的model\n",
        "                                      param_distribution, # 参数分布\n",
        "                                      n_iter = 10, # 我从这个param_distribution中sample出来多少个参数集合，这里生成10\n",
        "                                      cv = 3, # 训练集分成n份，n-1训练，最后一份验证.n就是cv的值，可以修改\n",
        "                                      n_jobs = 1) # 有多少任务在并行处理\n",
        "random_search_cv.fit(x_train_scaled, y_train, epochs = 100,\n",
        "                     validation_data = (x_valid_scaled, y_valid),\n",
        "                     callbacks = callbacks)\n",
        "\n",
        "# cross_validation: 训练集分成n份，n-1训练，最后一份验证.\n",
        "# 最后还会用所有数据训练一次"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 1.2357 - val_loss: 0.7356\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6631 - val_loss: 0.6412\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5840 - val_loss: 0.5854\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5349 - val_loss: 0.5366\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4992 - val_loss: 0.5068\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4713 - val_loss: 0.4832\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4522 - val_loss: 0.4604\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4331 - val_loss: 0.4417\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4158 - val_loss: 0.4369\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4011 - val_loss: 0.4150\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3893 - val_loss: 0.3966\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3799 - val_loss: 0.3884\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3718 - val_loss: 0.3864\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3658 - val_loss: 0.3809\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3631 - val_loss: 0.3762\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3589 - val_loss: 0.3709\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3555 - val_loss: 0.3687\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3528 - val_loss: 0.3781\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3510 - val_loss: 0.3654\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3505 - val_loss: 0.3702\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3527 - val_loss: 0.3595\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3412 - val_loss: 0.3644\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3381 - val_loss: 0.3526\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3354 - val_loss: 0.3516\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3322 - val_loss: 0.3487\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3326 - val_loss: 0.3452\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3288 - val_loss: 0.3458\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3284 - val_loss: 0.3459\n",
            "3870/3870 [==============================] - 0s 33us/sample - loss: 0.3259\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 1.0219 - val_loss: 0.6549\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5531 - val_loss: 0.5652\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4913 - val_loss: 0.5127\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4544 - val_loss: 0.4692\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4273 - val_loss: 0.4411\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4089 - val_loss: 0.4250\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3964 - val_loss: 0.4153\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3877 - val_loss: 0.4082\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3798 - val_loss: 0.3965\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3742 - val_loss: 0.3893\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3689 - val_loss: 0.3866\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3651 - val_loss: 0.3820\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3608 - val_loss: 0.3812\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3571 - val_loss: 0.3720\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3526 - val_loss: 0.3747\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3497 - val_loss: 0.3722\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3461 - val_loss: 0.3713\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3441 - val_loss: 0.3621\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3401 - val_loss: 0.3679\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3377 - val_loss: 0.3615\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3359 - val_loss: 0.3575\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3330 - val_loss: 0.3543\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3320 - val_loss: 0.3517\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3274 - val_loss: 0.3512\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3274 - val_loss: 0.3517\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3245 - val_loss: 0.4005\n",
            "3870/3870 [==============================] - 0s 33us/sample - loss: 0.3728\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 1.1909 - val_loss: 0.8093\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5799 - val_loss: 0.5888\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5089 - val_loss: 0.5406\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4646 - val_loss: 0.4857\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4339 - val_loss: 0.4540\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4132 - val_loss: 0.4380\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3943 - val_loss: 0.4230\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3844 - val_loss: 0.4138\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3758 - val_loss: 0.4118\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3652 - val_loss: 0.3923\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3585 - val_loss: 0.3963\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3526 - val_loss: 0.3865\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3540 - val_loss: 0.3879\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3517 - val_loss: 0.3791\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3459 - val_loss: 0.3724\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3374 - val_loss: 0.3694\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3330 - val_loss: 0.3693\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3352 - val_loss: 0.3641\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3290 - val_loss: 0.3611\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3297 - val_loss: 0.3691\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3278 - val_loss: 0.3635\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3246 - val_loss: 0.3656\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3174 - val_loss: 0.3502\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3173 - val_loss: 0.3562\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3169 - val_loss: 0.3634\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3166 - val_loss: 0.3473\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3090 - val_loss: 0.3470\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3104 - val_loss: 0.3461\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3547\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 5.2304 - val_loss: 5.0389\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 4.4555 - val_loss: 4.3111\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 3.8049 - val_loss: 3.6883\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 3.2355 - val_loss: 3.1336\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 2.7316 - val_loss: 2.6492\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 2.2999 - val_loss: 2.2400\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.9446 - val_loss: 1.9100\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.6673 - val_loss: 1.6577\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.4641 - val_loss: 1.4767\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.3243 - val_loss: 1.3536\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.2318 - val_loss: 1.2710\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 1.1706 - val_loss: 1.2142\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.1277 - val_loss: 1.1719\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 1.0948 - val_loss: 1.1378\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.0670 - val_loss: 1.1078\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 1.0420 - val_loss: 1.0802\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.0186 - val_loss: 1.0544\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9964 - val_loss: 1.0297\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9750 - val_loss: 1.0061\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9544 - val_loss: 0.9833\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9345 - val_loss: 0.9615\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9153 - val_loss: 0.9405\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8969 - val_loss: 0.9204\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8792 - val_loss: 0.9010\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8621 - val_loss: 0.8825\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 65us/sample - loss: 0.8456 - val_loss: 0.8650\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8299 - val_loss: 0.8484\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8150 - val_loss: 0.8326\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8009 - val_loss: 0.8178\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7877 - val_loss: 0.8039\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7751 - val_loss: 0.7906\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7632 - val_loss: 0.7783\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7520 - val_loss: 0.7668\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7415 - val_loss: 0.7560\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7316 - val_loss: 0.7460\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7223 - val_loss: 0.7366\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7135 - val_loss: 0.7279\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7052 - val_loss: 0.7197\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6974 - val_loss: 0.7122\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6901 - val_loss: 0.7051\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6832 - val_loss: 0.6986\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6768 - val_loss: 0.6924\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6708 - val_loss: 0.6867\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6652 - val_loss: 0.6814\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6599 - val_loss: 0.6765\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6550 - val_loss: 0.6718\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6503 - val_loss: 0.6674\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6459 - val_loss: 0.6634\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6418 - val_loss: 0.6595\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6379 - val_loss: 0.6560\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6342 - val_loss: 0.6526\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6307 - val_loss: 0.6494\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6273 - val_loss: 0.6463\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6242 - val_loss: 0.6434\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6211 - val_loss: 0.6406\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6181 - val_loss: 0.6380\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6153 - val_loss: 0.6353\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6126 - val_loss: 0.6328\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6099 - val_loss: 0.6304\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6074 - val_loss: 0.6280\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6049 - val_loss: 0.6256\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6024 - val_loss: 0.6233\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6000 - val_loss: 0.6210\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5976 - val_loss: 0.6188\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5953 - val_loss: 0.6166\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5930 - val_loss: 0.6145\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5908 - val_loss: 0.6124\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5887 - val_loss: 0.6104\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5867 - val_loss: 0.6085\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5847 - val_loss: 0.6065\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5827 - val_loss: 0.6046\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5809 - val_loss: 0.6028\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5790 - val_loss: 0.6010\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.5408\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 4.9562 - val_loss: 4.7774\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 4.1993 - val_loss: 3.9988\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 3.4541 - val_loss: 3.2391\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 2.7494 - val_loss: 2.5573\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 2.1620 - val_loss: 2.0327\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.7338 - val_loss: 1.6756\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.4533 - val_loss: 1.4539\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.2920 - val_loss: 1.3241\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.1919 - val_loss: 1.2344\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.1235 - val_loss: 1.1700\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 1.0705 - val_loss: 1.1213\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.0306 - val_loss: 1.0786\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9971 - val_loss: 1.0447\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9683 - val_loss: 1.0132\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9440 - val_loss: 0.9881\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9222 - val_loss: 0.9657\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9028 - val_loss: 0.9438\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8853 - val_loss: 0.9257\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8690 - val_loss: 0.9094\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8548 - val_loss: 0.8931\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8412 - val_loss: 0.8797\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8288 - val_loss: 0.8664\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8179 - val_loss: 0.8555\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8074 - val_loss: 0.8455\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7978 - val_loss: 0.8362\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7890 - val_loss: 0.8264\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7806 - val_loss: 0.8183\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7727 - val_loss: 0.8107\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7652 - val_loss: 0.8027\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7584 - val_loss: 0.7960\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7518 - val_loss: 0.7898\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7455 - val_loss: 0.7838\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7395 - val_loss: 0.7773\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7340 - val_loss: 0.7719\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7286 - val_loss: 0.7668\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7233 - val_loss: 0.7619\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.7184 - val_loss: 0.7572\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7136 - val_loss: 0.7527\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7090 - val_loss: 0.7483\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7046 - val_loss: 0.7435\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7004 - val_loss: 0.7395\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6963 - val_loss: 0.7356\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6923 - val_loss: 0.7318\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6884 - val_loss: 0.7281\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6845 - val_loss: 0.7245\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6809 - val_loss: 0.7210\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6772 - val_loss: 0.7176\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6738 - val_loss: 0.7143\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6703 - val_loss: 0.7110\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6669 - val_loss: 0.7078\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6636 - val_loss: 0.7046\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6603 - val_loss: 0.7016\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6571 - val_loss: 0.6985\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6540 - val_loss: 0.6955\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6508 - val_loss: 0.6922\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6479 - val_loss: 0.6893\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6448 - val_loss: 0.6864\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6418 - val_loss: 0.6836\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6389 - val_loss: 0.6809\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6360 - val_loss: 0.6782\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6332 - val_loss: 0.6755\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6304 - val_loss: 0.6728\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6277 - val_loss: 0.6702\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6249 - val_loss: 0.6676\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6223 - val_loss: 0.6649\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6196 - val_loss: 0.6624\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6170 - val_loss: 0.6598\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6144 - val_loss: 0.6573\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6119 - val_loss: 0.6547\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6094 - val_loss: 0.6523\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6068 - val_loss: 0.6497\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6044 - val_loss: 0.6473\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6019 - val_loss: 0.6450\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5994 - val_loss: 0.6426\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5971 - val_loss: 0.6403\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5947 - val_loss: 0.6379\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5923 - val_loss: 0.6356\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5900 - val_loss: 0.6334\n",
            "Epoch 79/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5877 - val_loss: 0.6312\n",
            "Epoch 80/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5854 - val_loss: 0.6289\n",
            "Epoch 81/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5832 - val_loss: 0.6268\n",
            "Epoch 82/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5809 - val_loss: 0.6246\n",
            "Epoch 83/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5787 - val_loss: 0.6225\n",
            "Epoch 84/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5766 - val_loss: 0.6204\n",
            "Epoch 85/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5744 - val_loss: 0.6183\n",
            "Epoch 86/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5723 - val_loss: 0.6163\n",
            "Epoch 87/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5702 - val_loss: 0.6143\n",
            "Epoch 88/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5681 - val_loss: 0.6123\n",
            "Epoch 89/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5661 - val_loss: 0.6103\n",
            "Epoch 90/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5641 - val_loss: 0.6084\n",
            "Epoch 91/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5621 - val_loss: 0.6065\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.5739\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 4.0587 - val_loss: 3.7944\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 3.0201 - val_loss: 2.8951\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 2.2505 - val_loss: 2.3104\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.7693 - val_loss: 1.9639\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 1.4863 - val_loss: 1.7462\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.3102 - val_loss: 1.5878\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 1.1876 - val_loss: 1.4586\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.0941 - val_loss: 1.3485\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 1.0185 - val_loss: 1.2542\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9560 - val_loss: 1.1754\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9038 - val_loss: 1.1079\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8601 - val_loss: 1.0503\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8227 - val_loss: 1.0008\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7906 - val_loss: 0.9562\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7623 - val_loss: 0.9175\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7374 - val_loss: 0.8839\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7156 - val_loss: 0.8538\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6966 - val_loss: 0.8272\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6795 - val_loss: 0.8040\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6647 - val_loss: 0.7822\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6519 - val_loss: 0.7632\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6406 - val_loss: 0.7463\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6307 - val_loss: 0.7317\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6220 - val_loss: 0.7188\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6142 - val_loss: 0.7072\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6074 - val_loss: 0.6970\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6014 - val_loss: 0.6882\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5961 - val_loss: 0.6800\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5912 - val_loss: 0.6728\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5868 - val_loss: 0.6661\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5828 - val_loss: 0.6602\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5791 - val_loss: 0.6548\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5758 - val_loss: 0.6500\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5727 - val_loss: 0.6456\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5699 - val_loss: 0.6416\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5673 - val_loss: 0.6377\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5648 - val_loss: 0.6343\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5625 - val_loss: 0.6310\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5603 - val_loss: 0.6281\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5582 - val_loss: 0.6251\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5562 - val_loss: 0.6226\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5544 - val_loss: 0.6202\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5527 - val_loss: 0.6179\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5510 - val_loss: 0.6157\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5494 - val_loss: 0.6136\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5478 - val_loss: 0.6117\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5464 - val_loss: 0.6098\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5450 - val_loss: 0.6080\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5436 - val_loss: 0.6063\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5423 - val_loss: 0.6047\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5409 - val_loss: 0.6031\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5397 - val_loss: 0.6017\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.5843\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 100us/sample - loss: 1.1341 - val_loss: 0.7319\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6565 - val_loss: 0.5897\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5524 - val_loss: 0.5053\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4661 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4262 - val_loss: 0.4253\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4065 - val_loss: 0.4095\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3981 - val_loss: 0.4033\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3871 - val_loss: 0.3878\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3807 - val_loss: 0.3836\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3752 - val_loss: 0.3835\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3689 - val_loss: 0.3738\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3645 - val_loss: 0.3785\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3607 - val_loss: 0.3649\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3564 - val_loss: 0.3692\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3534 - val_loss: 0.3639\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3515 - val_loss: 0.3601\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3602 - val_loss: 0.3577\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3452 - val_loss: 0.3533\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3428 - val_loss: 0.3498\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3382 - val_loss: 0.3564\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3348 - val_loss: 0.3610\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3345 - val_loss: 0.3452\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3293 - val_loss: 0.3434\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3290 - val_loss: 0.3428\n",
            "3870/3870 [==============================] - 0s 32us/sample - loss: 0.3205\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 1.0112 - val_loss: 0.6716\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5769 - val_loss: 0.5786\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5129 - val_loss: 0.5247\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4725 - val_loss: 0.4897\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4421 - val_loss: 0.4625\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4217 - val_loss: 0.4367\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4057 - val_loss: 0.4257\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3951 - val_loss: 0.4047\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3844 - val_loss: 0.3980\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3769 - val_loss: 0.3910\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3695 - val_loss: 0.3839\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3649 - val_loss: 0.3783\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3595 - val_loss: 0.3752\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3553 - val_loss: 0.3687\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3509 - val_loss: 0.3684\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3476 - val_loss: 0.3615\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3439 - val_loss: 0.3613\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3399 - val_loss: 0.3746\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3370 - val_loss: 0.3589\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3363 - val_loss: 0.3653\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3322 - val_loss: 0.3609\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3451\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 96us/sample - loss: 0.9972 - val_loss: 0.7469\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5894 - val_loss: 0.5863\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5097 - val_loss: 0.5261\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4650 - val_loss: 0.4768\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4240 - val_loss: 0.4472\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4038 - val_loss: 0.4367\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3906 - val_loss: 0.4298\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3796 - val_loss: 0.4187\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3726 - val_loss: 0.4050\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3651 - val_loss: 0.3960\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3601 - val_loss: 0.3870\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3558 - val_loss: 0.3815\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3510 - val_loss: 0.3837\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3463 - val_loss: 0.3720\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3412 - val_loss: 0.3764\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3397 - val_loss: 0.3656\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3360 - val_loss: 0.3640\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3325 - val_loss: 0.3682\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3280 - val_loss: 0.3600\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3256 - val_loss: 0.3627\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3236 - val_loss: 0.3593\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3209 - val_loss: 0.3503\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3191 - val_loss: 0.3515\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3159 - val_loss: 0.3538\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3623\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 91us/sample - loss: 1.1579 - val_loss: 0.6481\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5830 - val_loss: 0.5722\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5257 - val_loss: 0.5178\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4828 - val_loss: 0.4825\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4554 - val_loss: 0.4560\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4330 - val_loss: 0.4364\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4190 - val_loss: 0.4258\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4059 - val_loss: 0.4145\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3977 - val_loss: 0.4037\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3870 - val_loss: 0.3960\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3806 - val_loss: 0.4035\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3760 - val_loss: 0.3825\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3696 - val_loss: 0.3763\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3648 - val_loss: 0.3758\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3649 - val_loss: 0.3664\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3584 - val_loss: 0.3672\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3533 - val_loss: 0.3641\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3494 - val_loss: 0.3646\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3456 - val_loss: 0.3553\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3424 - val_loss: 0.3561\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3422 - val_loss: 0.3563\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3374 - val_loss: 0.3496\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3372 - val_loss: 0.3479\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3348 - val_loss: 0.3507\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3306\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 93us/sample - loss: 1.0956 - val_loss: 0.6612\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6770 - val_loss: 0.6333\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5685 - val_loss: 0.4846\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4469 - val_loss: 0.4603\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4179 - val_loss: 0.4363\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4123 - val_loss: 0.4268\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3923 - val_loss: 0.4057\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3830 - val_loss: 0.3972\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3761 - val_loss: 0.3892\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3685 - val_loss: 0.3870\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3647 - val_loss: 0.3793\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3565 - val_loss: 0.3749\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3522 - val_loss: 0.3724\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3490 - val_loss: 0.3672\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3461 - val_loss: 0.3630\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3440 - val_loss: 0.3800\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3404 - val_loss: 0.3631\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3384 - val_loss: 0.3585\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3362 - val_loss: 0.3588\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3317\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 1.0038 - val_loss: 0.6402\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5332 - val_loss: 0.5532\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4755 - val_loss: 0.5075\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4430 - val_loss: 0.4690\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4179 - val_loss: 0.4460\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4008 - val_loss: 0.4241\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3865 - val_loss: 0.4152\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3750 - val_loss: 0.4010\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3663 - val_loss: 0.3954\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3592 - val_loss: 0.3951\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3548 - val_loss: 0.3996\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3482 - val_loss: 0.3874\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3435 - val_loss: 0.3739\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3403 - val_loss: 0.3667\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3352 - val_loss: 0.3668\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3328 - val_loss: 0.3605\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3306 - val_loss: 0.3656\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3267 - val_loss: 0.3616\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3244 - val_loss: 0.3552\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3224 - val_loss: 0.3560\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3215 - val_loss: 0.3549\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3691\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 97us/sample - loss: 3.0116 - val_loss: 1.5419\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 1.1157 - val_loss: 0.9955\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8507 - val_loss: 0.8443\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7595 - val_loss: 0.7787\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7157 - val_loss: 0.7436\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6894 - val_loss: 0.7179\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6693 - val_loss: 0.6986\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6519 - val_loss: 0.6807\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6355 - val_loss: 0.6650\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6209 - val_loss: 0.6497\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6065 - val_loss: 0.6351\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5929 - val_loss: 0.6216\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5803 - val_loss: 0.6082\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5682 - val_loss: 0.5961\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5569 - val_loss: 0.5836\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5458 - val_loss: 0.5724\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5355 - val_loss: 0.5616\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5257 - val_loss: 0.5515\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5163 - val_loss: 0.5417\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5074 - val_loss: 0.5315\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4992 - val_loss: 0.5225\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4910 - val_loss: 0.5150\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4841 - val_loss: 0.5071\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4775 - val_loss: 0.5000\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4713 - val_loss: 0.4940\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4657 - val_loss: 0.4879\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4602 - val_loss: 0.4831\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4551 - val_loss: 0.4771\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4506 - val_loss: 0.4718\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4462 - val_loss: 0.4672\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4417 - val_loss: 0.4644\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4381 - val_loss: 0.4586\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4341 - val_loss: 0.4545\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4308 - val_loss: 0.4506\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4274 - val_loss: 0.4477\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4242 - val_loss: 0.4445\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4211 - val_loss: 0.4416\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4183 - val_loss: 0.4379\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4155 - val_loss: 0.4352\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4132 - val_loss: 0.4322\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4105 - val_loss: 0.4296\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4083 - val_loss: 0.4277\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4055 - val_loss: 0.4251\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4036 - val_loss: 0.4228\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4016 - val_loss: 0.4204\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3993 - val_loss: 0.4193\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3974 - val_loss: 0.4170\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3956 - val_loss: 0.4143\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3939 - val_loss: 0.4131\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3919 - val_loss: 0.4112\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3901 - val_loss: 0.4114\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3887 - val_loss: 0.4078\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.3704\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 2.7866 - val_loss: 1.4788\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.1171 - val_loss: 0.9989\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8671 - val_loss: 0.8599\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7629 - val_loss: 0.7958\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7097 - val_loss: 0.7575\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6770 - val_loss: 0.7284\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6522 - val_loss: 0.7036\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6307 - val_loss: 0.6816\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6112 - val_loss: 0.6609\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5933 - val_loss: 0.6418\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5771 - val_loss: 0.6237\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5624 - val_loss: 0.6072\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5490 - val_loss: 0.5931\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5374 - val_loss: 0.5805\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5266 - val_loss: 0.5702\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5169 - val_loss: 0.5580\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5075 - val_loss: 0.5458\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4996 - val_loss: 0.5392\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4922 - val_loss: 0.5290\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4846 - val_loss: 0.5200\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4788 - val_loss: 0.5146\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4732 - val_loss: 0.5073\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4676 - val_loss: 0.4984\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4623 - val_loss: 0.4929\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4573 - val_loss: 0.4890\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4537 - val_loss: 0.4830\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4489 - val_loss: 0.4796\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4454 - val_loss: 0.4720\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4419 - val_loss: 0.4695\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4381 - val_loss: 0.4647\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4351 - val_loss: 0.4602\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4323 - val_loss: 0.4565\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4289 - val_loss: 0.4530\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4260 - val_loss: 0.4500\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4237 - val_loss: 0.4465\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4212 - val_loss: 0.4435\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4184 - val_loss: 0.4415\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4164 - val_loss: 0.4372\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4138 - val_loss: 0.4344\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4116 - val_loss: 0.4325\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4094 - val_loss: 0.4298\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4074 - val_loss: 0.4271\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4053 - val_loss: 0.4250\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4032 - val_loss: 0.4220\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4011 - val_loss: 0.4200\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3998 - val_loss: 0.4183\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3978 - val_loss: 0.4167\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3961 - val_loss: 0.4144\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3947 - val_loss: 0.4127\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3928 - val_loss: 0.4109\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3906 - val_loss: 0.4097\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3901 - val_loss: 0.4076\n",
            "3870/3870 [==============================] - 0s 36us/sample - loss: 0.3871\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 3.2385 - val_loss: 1.7697\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.2050 - val_loss: 0.9772\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8318 - val_loss: 0.7842\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6853 - val_loss: 0.7038\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6230 - val_loss: 0.6678\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5919 - val_loss: 0.6481\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5724 - val_loss: 0.6329\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5582 - val_loss: 0.6207\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5465 - val_loss: 0.6100\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5363 - val_loss: 0.5993\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5272 - val_loss: 0.5910\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5192 - val_loss: 0.5823\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5117 - val_loss: 0.5738\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5045 - val_loss: 0.5650\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4975 - val_loss: 0.5580\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4911 - val_loss: 0.5503\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4847 - val_loss: 0.5433\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4786 - val_loss: 0.5364\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4727 - val_loss: 0.5296\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4670 - val_loss: 0.5228\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4613 - val_loss: 0.5165\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4560 - val_loss: 0.5099\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4508 - val_loss: 0.5040\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4459 - val_loss: 0.4987\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4409 - val_loss: 0.4935\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4363 - val_loss: 0.4878\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4316 - val_loss: 0.4830\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4272 - val_loss: 0.4783\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4231 - val_loss: 0.4741\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4191 - val_loss: 0.4680\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4154 - val_loss: 0.4644\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4115 - val_loss: 0.4598\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4083 - val_loss: 0.4562\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4050 - val_loss: 0.4517\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4015 - val_loss: 0.4486\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3982 - val_loss: 0.4438\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3957 - val_loss: 0.4409\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3927 - val_loss: 0.4379\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3899 - val_loss: 0.4368\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3873 - val_loss: 0.4317\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3851 - val_loss: 0.4291\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3826 - val_loss: 0.4266\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3805 - val_loss: 0.4244\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3782 - val_loss: 0.4220\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3765 - val_loss: 0.4191\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3741 - val_loss: 0.4196\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3726 - val_loss: 0.4157\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3708 - val_loss: 0.4130\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3687 - val_loss: 0.4116\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3669 - val_loss: 0.4099\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3656 - val_loss: 0.4074\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3643 - val_loss: 0.4060\n",
            "3870/3870 [==============================] - 0s 29us/sample - loss: 0.4121\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 91us/sample - loss: 1.3497 - val_loss: 0.8403\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8569 - val_loss: 0.6639\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7096 - val_loss: 0.6189\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5497 - val_loss: 0.5618\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5158 - val_loss: 0.5222\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4906 - val_loss: 0.5006\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4712 - val_loss: 0.4815\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4534 - val_loss: 0.4651\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4397 - val_loss: 0.4526\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4309 - val_loss: 0.4450\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4223 - val_loss: 0.4418\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4135 - val_loss: 0.4244\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4077 - val_loss: 0.4181\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4020 - val_loss: 0.4132\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3970 - val_loss: 0.4079\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3932 - val_loss: 0.4033\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3923 - val_loss: 0.3999\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3866 - val_loss: 0.3973\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3844 - val_loss: 0.3952\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3810 - val_loss: 0.3929\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3794 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3756 - val_loss: 0.3860\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3731 - val_loss: 0.3854\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3711 - val_loss: 0.3834\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3688 - val_loss: 0.3827\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3682 - val_loss: 0.3786\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3644 - val_loss: 0.3774\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.3602\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 90us/sample - loss: 1.3814 - val_loss: 0.7561\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7444 - val_loss: 0.6507\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5894 - val_loss: 0.5954\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5352 - val_loss: 0.5510\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4958 - val_loss: 0.5209\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4747 - val_loss: 0.5125\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4575 - val_loss: 0.4877\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4421 - val_loss: 0.4638\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4311 - val_loss: 0.4513\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4195 - val_loss: 0.4402\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4155 - val_loss: 0.4370\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4075 - val_loss: 0.4249\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4017 - val_loss: 0.4212\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3968 - val_loss: 0.4160\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3934 - val_loss: 0.4095\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3887 - val_loss: 0.4065\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3866 - val_loss: 0.4039\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3825 - val_loss: 0.3976\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3791 - val_loss: 0.3947\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3770 - val_loss: 0.3931\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3744 - val_loss: 0.3874\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3720 - val_loss: 0.3895\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3703 - val_loss: 0.3854\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3673 - val_loss: 0.3840\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3658 - val_loss: 0.3825\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3641 - val_loss: 0.3789\n",
            "3870/3870 [==============================] - 0s 34us/sample - loss: 0.3587\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 90us/sample - loss: 1.2406 - val_loss: 0.7857\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6620 - val_loss: 0.6778\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5824 - val_loss: 0.6101\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5302 - val_loss: 0.5657\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4922 - val_loss: 0.5267\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4722 - val_loss: 0.5025\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4465 - val_loss: 0.4860\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4307 - val_loss: 0.4647\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4195 - val_loss: 0.4534\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4109 - val_loss: 0.4492\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4050 - val_loss: 0.4362\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3950 - val_loss: 0.4265\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3887 - val_loss: 0.4205\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3858 - val_loss: 0.4176\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3853 - val_loss: 0.4123\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3792 - val_loss: 0.4078\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3743 - val_loss: 0.4048\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3705 - val_loss: 0.3984\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3698 - val_loss: 0.3950\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3648 - val_loss: 0.3922\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3575 - val_loss: 0.3890\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3578 - val_loss: 0.3873\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3538 - val_loss: 0.3860\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3506 - val_loss: 0.3826\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3484 - val_loss: 0.3801\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3464 - val_loss: 0.3815\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3442 - val_loss: 0.3768\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3461 - val_loss: 0.3734\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3432 - val_loss: 0.3717\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3392 - val_loss: 0.3712\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3394 - val_loss: 0.3692\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3351 - val_loss: 0.3700\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3348 - val_loss: 0.3666\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3355 - val_loss: 0.3659\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3783\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 99us/sample - loss: 4.1642 - val_loss: 3.5109\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 2.8580 - val_loss: 2.4956\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 2.1499 - val_loss: 1.9684\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.7885 - val_loss: 1.6896\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.5612 - val_loss: 1.4986\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.4048 - val_loss: 1.3616\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.2808 - val_loss: 1.2536\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 1.1811 - val_loss: 1.1652\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 1.0996 - val_loss: 1.0926\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.0313 - val_loss: 1.0309\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.9739 - val_loss: 0.9791\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.9262 - val_loss: 0.9371\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8873 - val_loss: 0.8998\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8534 - val_loss: 0.8688\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.8251 - val_loss: 0.8422\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8012 - val_loss: 0.8198\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7805 - val_loss: 0.8002\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7623 - val_loss: 0.7831\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7464 - val_loss: 0.7678\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7321 - val_loss: 0.7542\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7193 - val_loss: 0.7419\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7078 - val_loss: 0.7306\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6972 - val_loss: 0.7204\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6875 - val_loss: 0.7110\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6786 - val_loss: 0.7023\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6703 - val_loss: 0.6941\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6625 - val_loss: 0.6865\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6552 - val_loss: 0.6793\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6483 - val_loss: 0.6724\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6418 - val_loss: 0.6660\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6357 - val_loss: 0.6599\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6299 - val_loss: 0.6541\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6244 - val_loss: 0.6486\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6191 - val_loss: 0.6433\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6140 - val_loss: 0.6382\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6093 - val_loss: 0.6334\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6046 - val_loss: 0.6288\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6002 - val_loss: 0.6243\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5960 - val_loss: 0.6201\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5919 - val_loss: 0.6159\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5879 - val_loss: 0.6119\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5840 - val_loss: 0.6080\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5802 - val_loss: 0.6043\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5766 - val_loss: 0.6007\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5730 - val_loss: 0.5970\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5696 - val_loss: 0.5936\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5663 - val_loss: 0.5902\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5630 - val_loss: 0.5869\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5599 - val_loss: 0.5838\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5568 - val_loss: 0.5806\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5538 - val_loss: 0.5776\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5509 - val_loss: 0.5747\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5481 - val_loss: 0.5717\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5454 - val_loss: 0.5689\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5426 - val_loss: 0.5662\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5401 - val_loss: 0.5635\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5374 - val_loss: 0.5611\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5350 - val_loss: 0.5584\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5326 - val_loss: 0.5559\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5302 - val_loss: 0.5535\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5279 - val_loss: 0.5511\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5256 - val_loss: 0.5488\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5234 - val_loss: 0.5466\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5212 - val_loss: 0.5443\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5191 - val_loss: 0.5422\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5171 - val_loss: 0.5401\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5151 - val_loss: 0.5380\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5129 - val_loss: 0.5360\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5112 - val_loss: 0.5340\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5093 - val_loss: 0.5321\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5075 - val_loss: 0.5302\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5057 - val_loss: 0.5283\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5040 - val_loss: 0.5265\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5022 - val_loss: 0.5248\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4668\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 95us/sample - loss: 4.8051 - val_loss: 4.4404\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 3.7812 - val_loss: 3.5024\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 2.9547 - val_loss: 2.7279\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 2.3001 - val_loss: 2.1446\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 1.8366 - val_loss: 1.7560\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 1.5470 - val_loss: 1.5294\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 1.3761 - val_loss: 1.3938\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 1.2704 - val_loss: 1.3065\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 1.1933 - val_loss: 1.2375\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 1.1306 - val_loss: 1.1793\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.0768 - val_loss: 1.1279\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.0288 - val_loss: 1.0810\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9856 - val_loss: 1.0382\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.9463 - val_loss: 0.9987\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.9102 - val_loss: 0.9620\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8763 - val_loss: 0.9286\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8457 - val_loss: 0.8981\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8179 - val_loss: 0.8705\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7929 - val_loss: 0.8455\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7705 - val_loss: 0.8231\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7506 - val_loss: 0.8031\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7328 - val_loss: 0.7853\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7170 - val_loss: 0.7694\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7031 - val_loss: 0.7553\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6907 - val_loss: 0.7428\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6798 - val_loss: 0.7317\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6703 - val_loss: 0.7218\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6616 - val_loss: 0.7128\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6539 - val_loss: 0.7048\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6470 - val_loss: 0.6975\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6406 - val_loss: 0.6907\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 65us/sample - loss: 0.6347 - val_loss: 0.6846\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6293 - val_loss: 0.6788\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6242 - val_loss: 0.6735\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6196 - val_loss: 0.6686\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6151 - val_loss: 0.6639\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6109 - val_loss: 0.6595\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6069 - val_loss: 0.6552\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6031 - val_loss: 0.6512\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5993 - val_loss: 0.6473\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5958 - val_loss: 0.6436\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5923 - val_loss: 0.6400\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5890 - val_loss: 0.6365\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5857 - val_loss: 0.6330\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5826 - val_loss: 0.6297\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5795 - val_loss: 0.6264\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5766 - val_loss: 0.6232\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5736 - val_loss: 0.6200\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5708 - val_loss: 0.6169\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5679 - val_loss: 0.6139\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5652 - val_loss: 0.6110\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5625 - val_loss: 0.6080\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5599 - val_loss: 0.6052\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5573 - val_loss: 0.6024\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5548 - val_loss: 0.5996\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5523 - val_loss: 0.5969\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5498 - val_loss: 0.5943\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5474 - val_loss: 0.5916\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5451 - val_loss: 0.5890\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5427 - val_loss: 0.5864\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5404 - val_loss: 0.5839\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5381 - val_loss: 0.5814\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5359 - val_loss: 0.5790\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5337 - val_loss: 0.5765\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5315 - val_loss: 0.5741\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5294 - val_loss: 0.5718\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5273 - val_loss: 0.5695\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5253 - val_loss: 0.5672\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5233 - val_loss: 0.5650\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5213 - val_loss: 0.5628\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5194 - val_loss: 0.5606\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5175 - val_loss: 0.5585\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5156 - val_loss: 0.5564\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5138 - val_loss: 0.5543\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5120 - val_loss: 0.5523\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5102 - val_loss: 0.5503\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5085 - val_loss: 0.5483\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5067 - val_loss: 0.5464\n",
            "Epoch 79/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5051 - val_loss: 0.5445\n",
            "Epoch 80/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5034 - val_loss: 0.5427\n",
            "Epoch 81/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5018 - val_loss: 0.5409\n",
            "Epoch 82/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5002 - val_loss: 0.5391\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.5002\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 102us/sample - loss: 4.2759 - val_loss: 3.6279\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 2.8030 - val_loss: 2.4472\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.9266 - val_loss: 1.8358\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.4960 - val_loss: 1.5168\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 1.2629 - val_loss: 1.3077\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.1129 - val_loss: 1.1665\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.0103 - val_loss: 1.0703\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.9364 - val_loss: 0.9996\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8803 - val_loss: 0.9469\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8372 - val_loss: 0.9063\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8037 - val_loss: 0.8753\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7778 - val_loss: 0.8515\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.7575 - val_loss: 0.8328\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7410 - val_loss: 0.8179\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7276 - val_loss: 0.8056\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7164 - val_loss: 0.7956\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7071 - val_loss: 0.7871\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6989 - val_loss: 0.7798\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6919 - val_loss: 0.7731\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6856 - val_loss: 0.7671\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6799 - val_loss: 0.7615\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6747 - val_loss: 0.7563\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6698 - val_loss: 0.7514\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6651 - val_loss: 0.7466\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6608 - val_loss: 0.7421\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6566 - val_loss: 0.7377\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6526 - val_loss: 0.7334\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6487 - val_loss: 0.7294\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6450 - val_loss: 0.7253\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6415 - val_loss: 0.7213\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6379 - val_loss: 0.7175\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6345 - val_loss: 0.7137\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6313 - val_loss: 0.7100\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6280 - val_loss: 0.7063\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6249 - val_loss: 0.7028\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6218 - val_loss: 0.6993\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6188 - val_loss: 0.6959\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6159 - val_loss: 0.6925\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6129 - val_loss: 0.6892\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6102 - val_loss: 0.6859\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6074 - val_loss: 0.6827\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6047 - val_loss: 0.6796\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6020 - val_loss: 0.6766\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5994 - val_loss: 0.6736\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5969 - val_loss: 0.6706\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5944 - val_loss: 0.6677\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5919 - val_loss: 0.6648\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5895 - val_loss: 0.6620\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5870 - val_loss: 0.6592\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5847 - val_loss: 0.6564\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5824 - val_loss: 0.6537\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5801 - val_loss: 0.6510\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5778 - val_loss: 0.6484\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5755 - val_loss: 0.6457\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5733 - val_loss: 0.6431\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5711 - val_loss: 0.6406\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5689 - val_loss: 0.6381\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5668 - val_loss: 0.6356\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5647 - val_loss: 0.6331\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5625 - val_loss: 0.6308\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5606 - val_loss: 0.6282\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5585 - val_loss: 0.6259\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5565 - val_loss: 0.6236\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5545 - val_loss: 0.6213\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5525 - val_loss: 0.6190\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5506 - val_loss: 0.6166\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5486 - val_loss: 0.6144\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5467 - val_loss: 0.6122\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5448 - val_loss: 0.6101\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5429 - val_loss: 0.6078\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5410 - val_loss: 0.6058\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5391 - val_loss: 0.6037\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5373 - val_loss: 0.6015\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5355 - val_loss: 0.5994\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5337 - val_loss: 0.5973\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5320 - val_loss: 0.5953\n",
            "Epoch 77/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5301 - val_loss: 0.5934\n",
            "Epoch 78/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5285 - val_loss: 0.5913\n",
            "Epoch 79/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5267 - val_loss: 0.5893\n",
            "Epoch 80/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5251 - val_loss: 0.5873\n",
            "Epoch 81/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5233 - val_loss: 0.5854\n",
            "Epoch 82/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5216 - val_loss: 0.5834\n",
            "Epoch 83/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5200 - val_loss: 0.5815\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.5763\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 89us/sample - loss: 1.0732 - val_loss: 0.6110\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5475 - val_loss: 0.5256\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4913 - val_loss: 0.4860\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4623 - val_loss: 0.4684\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4388 - val_loss: 0.4377\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4343 - val_loss: 0.4288\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4217 - val_loss: 0.4205\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4221 - val_loss: 0.4449\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4250 - val_loss: 0.4246\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4099 - val_loss: 0.4158\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4047 - val_loss: 0.4083\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4010 - val_loss: 0.4026\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3974 - val_loss: 0.3993\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3920 - val_loss: 0.4069\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3926 - val_loss: 0.3906\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3905 - val_loss: 0.4166\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3911 - val_loss: 0.3959\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3875 - val_loss: 0.3904\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3841 - val_loss: 0.3960\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3823 - val_loss: 0.3810\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3585\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 89us/sample - loss: 1.0016 - val_loss: 1.6739\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5722 - val_loss: 0.5508\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4964 - val_loss: 0.5117\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4736 - val_loss: 0.4975\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4572 - val_loss: 0.4717\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4546 - val_loss: 0.4711\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4435 - val_loss: 0.4579\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4298 - val_loss: 0.4412\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4226 - val_loss: 0.4383\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4151 - val_loss: 0.4261\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4108 - val_loss: 0.4257\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4061 - val_loss: 0.4143\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4042 - val_loss: 0.4115\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4007 - val_loss: 0.4154\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3992 - val_loss: 0.4156\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3969 - val_loss: 0.4009\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3950 - val_loss: 0.4016\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3927 - val_loss: 0.4147\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3948 - val_loss: 0.3993\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3898 - val_loss: 0.4045\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3892 - val_loss: 0.3981\n",
            "3870/3870 [==============================] - 0s 26us/sample - loss: 0.3889\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 118us/sample - loss: 1.0400 - val_loss: 0.7116\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6167 - val_loss: 0.6194\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5348 - val_loss: 0.5491\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4850 - val_loss: 0.5018\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4551 - val_loss: 0.4731\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4368 - val_loss: 0.4552\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4208 - val_loss: 0.4518\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4144 - val_loss: 0.4525\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4057 - val_loss: 0.4326\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4003 - val_loss: 0.4236\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3975 - val_loss: 0.4131\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3907 - val_loss: 0.4121\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3898 - val_loss: 0.4078\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3838 - val_loss: 0.4102\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3802 - val_loss: 0.4359\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3774 - val_loss: 0.4092\n",
            "3870/3870 [==============================] - 0s 28us/sample - loss: 0.4175\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 92us/sample - loss: 4.5707 - val_loss: 2.6106\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 1.6421 - val_loss: 1.1588\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9684 - val_loss: 0.8823\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8100 - val_loss: 0.7843\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7416 - val_loss: 0.7373\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7051 - val_loss: 0.7112\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6827 - val_loss: 0.6951\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6677 - val_loss: 0.6838\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6566 - val_loss: 0.6751\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6476 - val_loss: 0.6676\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6398 - val_loss: 0.6609\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6328 - val_loss: 0.6545\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6263 - val_loss: 0.6487\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6203 - val_loss: 0.6429\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6147 - val_loss: 0.6373\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6092 - val_loss: 0.6321\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6041 - val_loss: 0.6270\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5992 - val_loss: 0.6221\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5942 - val_loss: 0.6176\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5895 - val_loss: 0.6124\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5849 - val_loss: 0.6076\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5803 - val_loss: 0.6030\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5758 - val_loss: 0.5983\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5713 - val_loss: 0.5939\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5669 - val_loss: 0.5897\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5627 - val_loss: 0.5850\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5586 - val_loss: 0.5805\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5542 - val_loss: 0.5762\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5503 - val_loss: 0.5720\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5464 - val_loss: 0.5678\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5423 - val_loss: 0.5638\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5385 - val_loss: 0.5594\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5345 - val_loss: 0.5554\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5307 - val_loss: 0.5515\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5271 - val_loss: 0.5477\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5234 - val_loss: 0.5440\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5198 - val_loss: 0.5403\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5164 - val_loss: 0.5368\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5129 - val_loss: 0.5332\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5097 - val_loss: 0.5298\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5064 - val_loss: 0.5265\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5034 - val_loss: 0.5232\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5003 - val_loss: 0.5198\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4973 - val_loss: 0.5167\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4944 - val_loss: 0.5137\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4916 - val_loss: 0.5108\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4890 - val_loss: 0.5077\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4863 - val_loss: 0.5050\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4836 - val_loss: 0.5023\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4811 - val_loss: 0.4995\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4787 - val_loss: 0.4969\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4762 - val_loss: 0.4943\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4739 - val_loss: 0.4917\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4716 - val_loss: 0.4896\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4692 - val_loss: 0.4872\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4672 - val_loss: 0.4851\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4650 - val_loss: 0.4829\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4630 - val_loss: 0.4801\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4608 - val_loss: 0.4778\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4587 - val_loss: 0.4762\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4569 - val_loss: 0.4738\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4549 - val_loss: 0.4717\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4532 - val_loss: 0.4694\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4512 - val_loss: 0.4673\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4495 - val_loss: 0.4652\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4476 - val_loss: 0.4633\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4460 - val_loss: 0.4615\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4442 - val_loss: 0.4598\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4426 - val_loss: 0.4579\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4410 - val_loss: 0.4562\n",
            "3870/3870 [==============================] - 0s 32us/sample - loss: 0.4163\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 89us/sample - loss: 2.4886 - val_loss: 1.5267\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.2239 - val_loss: 1.1133\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.9726 - val_loss: 0.9758\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8804 - val_loss: 0.9152\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8356 - val_loss: 0.8784\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8050 - val_loss: 0.8515\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7815 - val_loss: 0.8295\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7614 - val_loss: 0.8100\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7442 - val_loss: 0.7930\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7285 - val_loss: 0.7774\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7137 - val_loss: 0.7618\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7006 - val_loss: 0.7476\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6877 - val_loss: 0.7342\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6757 - val_loss: 0.7219\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6642 - val_loss: 0.7093\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6529 - val_loss: 0.6980\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6425 - val_loss: 0.6863\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6323 - val_loss: 0.6754\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6224 - val_loss: 0.6651\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6130 - val_loss: 0.6547\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6042 - val_loss: 0.6450\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5953 - val_loss: 0.6356\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5871 - val_loss: 0.6268\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5791 - val_loss: 0.6185\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5718 - val_loss: 0.6103\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5645 - val_loss: 0.6026\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5578 - val_loss: 0.5953\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5511 - val_loss: 0.5884\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5450 - val_loss: 0.5820\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5391 - val_loss: 0.5759\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5338 - val_loss: 0.5699\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5285 - val_loss: 0.5642\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5235 - val_loss: 0.5588\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5188 - val_loss: 0.5536\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5145 - val_loss: 0.5490\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5102 - val_loss: 0.5443\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5061 - val_loss: 0.5402\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5024 - val_loss: 0.5363\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4988 - val_loss: 0.5326\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4955 - val_loss: 0.5287\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4919 - val_loss: 0.5254\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4889 - val_loss: 0.5220\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4857 - val_loss: 0.5198\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4829 - val_loss: 0.5160\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4801 - val_loss: 0.5133\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4775 - val_loss: 0.5102\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4750 - val_loss: 0.5075\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4724 - val_loss: 0.5053\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4701 - val_loss: 0.5030\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4677 - val_loss: 0.5009\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4656 - val_loss: 0.4977\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4633 - val_loss: 0.4957\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4613 - val_loss: 0.4932\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4589 - val_loss: 0.4919\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4571 - val_loss: 0.4889\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4550 - val_loss: 0.4872\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4528 - val_loss: 0.4849\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4513 - val_loss: 0.4823\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4493 - val_loss: 0.4807\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4474 - val_loss: 0.4783\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4453 - val_loss: 0.4764\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4436 - val_loss: 0.4754\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4419 - val_loss: 0.4726\n",
            "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4442\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 94us/sample - loss: 4.4823 - val_loss: 3.3606\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 2.3778 - val_loss: 1.9507\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.5149 - val_loss: 1.4723\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.2493 - val_loss: 1.2877\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.1292 - val_loss: 1.1702\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.0413 - val_loss: 1.0773\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9663 - val_loss: 0.9972\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 1s 67us/sample - loss: 0.8983 - val_loss: 0.9268\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.8376 - val_loss: 0.8655\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.7843 - val_loss: 0.8144\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7396 - val_loss: 0.7731\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7033 - val_loss: 0.7408\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6742 - val_loss: 0.7169\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6514 - val_loss: 0.6985\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6333 - val_loss: 0.6827\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6184 - val_loss: 0.6707\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6054 - val_loss: 0.6590\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5941 - val_loss: 0.6488\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5838 - val_loss: 0.6389\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5743 - val_loss: 0.6296\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5652 - val_loss: 0.6209\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5568 - val_loss: 0.6118\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5486 - val_loss: 0.6030\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5408 - val_loss: 0.5945\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5333 - val_loss: 0.5863\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5258 - val_loss: 0.5788\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5188 - val_loss: 0.5710\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5121 - val_loss: 0.5638\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5057 - val_loss: 0.5565\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4996 - val_loss: 0.5497\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4937 - val_loss: 0.5431\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4881 - val_loss: 0.5368\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4828 - val_loss: 0.5309\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4779 - val_loss: 0.5253\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4730 - val_loss: 0.5200\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4685 - val_loss: 0.5149\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4644 - val_loss: 0.5100\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4603 - val_loss: 0.5055\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4566 - val_loss: 0.5010\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4531 - val_loss: 0.4968\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4496 - val_loss: 0.4927\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4464 - val_loss: 0.4895\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4435 - val_loss: 0.4855\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4407 - val_loss: 0.4820\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4379 - val_loss: 0.4788\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4353 - val_loss: 0.4760\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4329 - val_loss: 0.4726\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4305 - val_loss: 0.4697\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4284 - val_loss: 0.4673\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4263 - val_loss: 0.4649\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4242 - val_loss: 0.4623\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4223 - val_loss: 0.4599\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4206 - val_loss: 0.4575\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4187 - val_loss: 0.4553\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4171 - val_loss: 0.4532\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4156 - val_loss: 0.4515\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4140 - val_loss: 0.4498\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4124 - val_loss: 0.4480\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4111 - val_loss: 0.4458\n",
            "3870/3870 [==============================] - 0s 29us/sample - loss: 0.4520\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 85us/sample - loss: 3.3060 - val_loss: 2.6601\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 2.1368 - val_loss: 1.7323\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.4662 - val_loss: 1.2435\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.1320 - val_loss: 1.0204\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9711 - val_loss: 0.9167\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8880 - val_loss: 0.8614\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8379 - val_loss: 0.8268\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8029 - val_loss: 0.8015\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7763 - val_loss: 0.7821\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7556 - val_loss: 0.7659\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7383 - val_loss: 0.7520\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7239 - val_loss: 0.7401\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7115 - val_loss: 0.7298\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7006 - val_loss: 0.7205\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6911 - val_loss: 0.7120\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6826 - val_loss: 0.7045\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6750 - val_loss: 0.6974\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6680 - val_loss: 0.6910\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6617 - val_loss: 0.6851\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6561 - val_loss: 0.6797\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6508 - val_loss: 0.6745\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6458 - val_loss: 0.6695\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6411 - val_loss: 0.6647\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6367 - val_loss: 0.6602\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6325 - val_loss: 0.6558\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6286 - val_loss: 0.6516\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6247 - val_loss: 0.6476\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6211 - val_loss: 0.6437\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6176 - val_loss: 0.6400\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6143 - val_loss: 0.6365\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6111 - val_loss: 0.6330\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6080 - val_loss: 0.6296\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6051 - val_loss: 0.6263\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6022 - val_loss: 0.6231\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5993 - val_loss: 0.6200\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5966 - val_loss: 0.6171\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5940 - val_loss: 0.6142\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5915 - val_loss: 0.6114\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5890 - val_loss: 0.6086\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5866 - val_loss: 0.6060\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5844 - val_loss: 0.6034\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5821 - val_loss: 0.6009\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5800 - val_loss: 0.5984\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5778 - val_loss: 0.5960\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5758 - val_loss: 0.5937\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5738 - val_loss: 0.5915\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5717 - val_loss: 0.5893\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5699 - val_loss: 0.5871\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5679 - val_loss: 0.5851\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5661 - val_loss: 0.5830\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5642 - val_loss: 0.5810\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5625 - val_loss: 0.5790\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5607 - val_loss: 0.5771\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5590 - val_loss: 0.5753\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5574 - val_loss: 0.5735\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5557 - val_loss: 0.5716\n",
            "3870/3870 [==============================] - 0s 31us/sample - loss: 0.5142\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 83us/sample - loss: 4.8545 - val_loss: 4.5056\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 3.9548 - val_loss: 3.6512\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 3.2027 - val_loss: 2.9457\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 2.6001 - val_loss: 2.3864\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 2.1371 - val_loss: 1.9638\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.7985 - val_loss: 1.6618\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.5669 - val_loss: 1.4619\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 1.4144 - val_loss: 1.3298\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 1.3137 - val_loss: 1.2421\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.2471 - val_loss: 1.1833\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 1.2005 - val_loss: 1.1444\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.1641 - val_loss: 1.1127\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.1348 - val_loss: 1.0871\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 1.1104 - val_loss: 1.0659\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 1.0888 - val_loss: 1.0477\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 1.0687 - val_loss: 1.0309\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.0500 - val_loss: 1.0154\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.0322 - val_loss: 1.0010\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 1.0149 - val_loss: 0.9864\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.9990 - val_loss: 0.9725\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.9836 - val_loss: 0.9595\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9687 - val_loss: 0.9470\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.9544 - val_loss: 0.9350\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9408 - val_loss: 0.9241\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.9276 - val_loss: 0.9135\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9149 - val_loss: 0.9034\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9028 - val_loss: 0.8938\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8913 - val_loss: 0.8848\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8804 - val_loss: 0.8766\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8698 - val_loss: 0.8685\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8598 - val_loss: 0.8608\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8505 - val_loss: 0.8539\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8415 - val_loss: 0.8473\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8331 - val_loss: 0.8410\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8251 - val_loss: 0.8352\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.8175 - val_loss: 0.8297\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8104 - val_loss: 0.8246\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8037 - val_loss: 0.8198\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7974 - val_loss: 0.8153\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7915 - val_loss: 0.8110\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7859 - val_loss: 0.8069\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7807 - val_loss: 0.8031\n",
            "Epoch 43/100\n",
            "4096/7740 [==============>...............] - ETA: 0s - loss: 0.7825"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-X2bd56yMR7",
        "colab_type": "code",
        "outputId": "b5c0f508-8953-48ff-8c96-03a6146319eb",
        "colab": {}
      },
      "source": [
        "print(random_search_cv.best_params_)\n",
        "print(random_search_cv.best_score_)\n",
        "print(random_search_cv.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hidden_layers': 4, 'layer_size': 44, 'learning_rate': 0.0009577195482517434}\n",
            "-0.38287415603026553\n",
            "<keras.wrappers.scikit_learn.KerasRegressor object at 0x138dbc080>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr85r5Y2yMR-",
        "colab_type": "code",
        "outputId": "56a3a3cd-c273-4920-c7f6-0f9eb810c0d7",
        "colab": {}
      },
      "source": [
        "model = random_search_cv.best_estimator_.model\n",
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 30us/sample - loss: 0.3790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3790317230446394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XPFNi_JyMSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2661148d-a0ba-4558-c006-8bbba1c4a63a"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "reciprocal.rvs(1e-4, 1e-2, size = 10) # 每个数都是在1e-4 和 1e-2之间"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00027773, 0.0020727 , 0.00994371, 0.0029788 , 0.00151346,\n",
              "       0.0030166 , 0.0011623 , 0.00015027, 0.00028363, 0.00041566])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}