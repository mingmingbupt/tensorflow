{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf1_dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf1_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ePqfyhTjEQ",
        "colab_type": "code",
        "outputId": "b7919900-34fd-4865-8b50-044af9967ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 1.0.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 1.15.2\n",
            "tensorflow.python.keras.api._v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlFv8MZBTjEV",
        "colab_type": "code",
        "outputId": "669a37fc-9489-4695-dbff-0d820b26e93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
        "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
        "\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28) (5000,)\n",
            "(55000, 28, 28) (55000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObMt7OfoTjEX",
        "colab_type": "code",
        "outputId": "c287e47c-0a3d-469d-be53-fed3a6a37d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(np.max(x_train), np.min(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDgv9iETjEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = (x - u) / std\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# x_train: [None, 28, 28] -> [None, 784]\n",
        "x_train_scaled = scaler.fit_transform(\n",
        "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_valid_scaled = scaler.transform(\n",
        "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_test_scaled = scaler.transform(\n",
        "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "\n",
        "y_train = np.asarray(y_train, dtype = np.int64) #更改numpy的数据类型\n",
        "y_valid = np.asarray(y_valid, dtype = np.int64)\n",
        "y_test = np.asarray(y_test, dtype = np.int64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KpGJNbTjEc",
        "colab_type": "code",
        "outputId": "4eda32bb-fa4d-4c6a-f16c-dd24f6014354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(np.max(x_train_scaled), np.min(x_train_scaled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0231433 -0.8105136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOiAfKR8TjEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(images, labels, epochs, batch_size, shuffle = True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZkVvSmDTjEh",
        "colab_type": "code",
        "outputId": "e0846db4-d57e-4a7c-e874-67f275a1703d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 10\n",
        "dataset = make_dataset(x_train_scaled, y_train,\n",
        "                       epochs = epochs,\n",
        "                       batch_size = batch_size)\n",
        "for data, label in dataset.take(1):\n",
        "    print(data)\n",
        "    print(label)\n",
        "\n",
        "#像tensorflow2.0那样是没法工作的"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-64c99b9fccb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        batch_size = batch_size)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rw33DVkTjEj",
        "colab_type": "code",
        "outputId": "81612b24-e7b8-40e5-ccbd-4e2a73c1be3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 10\n",
        "dataset = make_dataset(x_train_scaled, y_train,\n",
        "                       epochs = epochs,\n",
        "                       batch_size = batch_size)\n",
        "# 1. auto initialization\n",
        "# 2. can't be re-initialized. make_initializable_iterator\n",
        "dataset_iter = dataset.make_one_shot_iterator() #他可以创建一个遍历器，去遍历这个dataset\n",
        "#得到这个dataset_iter之后，我们可以通过get_next()函数来得到下一组的数据\n",
        "#make_one_shot_iterator特点\n",
        "#1.自动初始化，我们在打开session的时候并没有调用初始化函数，这个dataset_iter就可以直接用了\n",
        "#2.不能够被重新初始化，这里面我们的dataset是使用x_train_scaled，y_train来组成的\n",
        "# 如果想用别的数据来重新初始化这个dataset那么是不可以的。\n",
        "# 而另外一个API make_initializable_iterator则是可以的\n",
        "\n",
        "x, y = dataset_iter.get_next() #x y还不是具体的值，还是个tensor\n",
        "with tf.Session() as sess:\n",
        "  for i in range(5):\n",
        "    x_val, y_val = sess.run([x, y])\n",
        "    print(x_val)\n",
        "    print(y_val)\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.8105136  -0.8105136  -0.8105136  ... -0.8105136  -0.8105136\n",
            "  -0.8105136 ]\n",
            " [-0.8105136  -0.8105136  -0.8105136  ... -0.8105136  -0.8105136\n",
            "  -0.8105136 ]\n",
            " [-0.8105136  -0.8105136  -0.8105136  ... -0.8105136  -0.8105136\n",
            "  -0.8105136 ]\n",
            " ...\n",
            " [-0.8105136  -0.8105136  -0.8105136  ...  0.20071293 -0.5549289\n",
            "  -0.8105136 ]\n",
            " [-0.8105136  -0.8105136  -0.8105136  ... -0.8105136  -0.8105136\n",
            "  -0.8105136 ]\n",
            " [-0.8105136  -0.8105136  -0.8105136  ... -0.8105136  -0.8105136\n",
            "  -0.8105136 ]]\n",
            "[9 1 8 0 5 4 6 7 7 5 2 1 0 7 9 0 0 4 0 2]\n",
            "[[-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " ...\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]]\n",
            "[3 4 9 8 2 8 3 5 8 7 4 4 1 8 7 0 4 5 9 8]\n",
            "[[-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " ...\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]]\n",
            "[1 3 3 9 5 5 6 1 0 6 7 8 8 7 5 9 4 3 1 7]\n",
            "[[-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " ...\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]]\n",
            "[5 3 1 9 8 7 1 5 2 2 8 5 8 4 2 7 1 7 9 1]\n",
            "[[-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " ...\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]\n",
            " [-0.8105136 -0.8105136 -0.8105136 ... -0.8105136 -0.8105136 -0.8105136]]\n",
            "[6 3 9 1 3 1 0 2 3 6 8 2 8 1 6 9 7 1 7 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4vU1yyfTjEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_units = [100, 100]\n",
        "class_num = 10\n",
        "\n",
        "#这里面x和y已经是对应的数据和label的tensor了\n",
        "input_for_next_layer = x #=x相当于把我们的dataset接入到我们的计算图中来了\n",
        "for hidden_unit in hidden_units:\n",
        "    input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                           hidden_unit,\n",
        "                                           activation=tf.nn.relu)\n",
        "logits = tf.layers.dense(input_for_next_layer,\n",
        "                         class_num)\n",
        "# last_hidden_output * W(logits) -> softmax -> prob\n",
        "# 1. logit -> softmax -> prob\n",
        "# 2. labels -> one_hot\n",
        "# 3. calculate cross entropy\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels = y,\n",
        "                                              logits = logits)\n",
        "# get accuracy.\n",
        "prediction = tf.argmax(logits, 1)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LQr4KFRTjEo",
        "colab_type": "code",
        "outputId": "90c0e5b0-02f6-4aeb-8d72-2c80d6b90b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(x) #x变成了Iterator tensor\n",
        "print(logits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"IteratorGetNext_9:0\", shape=(?, 784), dtype=float32)\n",
            "Tensor(\"dense_5/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNo2e2Y3TjEq",
        "colab_type": "code",
        "outputId": "0c36be64-085a-4527-9bec-1aefbe4e152e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# session\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(epochs):\n",
        "        for step in range(train_steps_per_epoch):\n",
        "            #x_val, y_val = sess.run([x, y])\n",
        "            #print(x_val.shape)\n",
        "            #print(y_val.shape)\n",
        "           \n",
        "            loss_val, accuracy_val, _ = sess.run(\n",
        "                [loss, accuracy, train_op])\n",
        "            print('\\r[Train] epoch: %d, step: %d, loss: %3.5f, accuracy: %2.2f' % (\n",
        "                epoch, step, loss_val, accuracy_val), end=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] epoch: 9, step: 2749, loss: 0.60225, accuracy: 0.85"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L9BNVf0TjEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}