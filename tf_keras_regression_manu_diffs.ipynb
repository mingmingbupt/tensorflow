{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf_keras_regression-manu-diffs.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf_keras_regression_manu_diffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBfaDDhwAxc2",
        "colab_type": "code",
        "outputId": "f4b5fe54-922f-439c-a4f1-8362ec2719c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc1\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 0.25.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 2.2.0-rc1\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqYp6m8MAxc6",
        "colab_type": "code",
        "outputId": "16227c7d-34e4-4b31-d91f-fd133e3b9e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXgcemWSAxc-",
        "colab_type": "code",
        "outputId": "d47d0a62-bd48-401d-be3e-35b7f7820f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2EwlZiAxdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2R1qoqpAxdC",
        "colab_type": "code",
        "outputId": "72bce558-1fee-44df-9755-16810ceab954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# metric使用\n",
        "# 这里使用的metric是均方差，即差的平方和的均值\n",
        "# 看下使用例子\n",
        "\n",
        "metric = keras.metrics.MeanSquaredError()\n",
        "print(metric([5.], [2.])) # 直接像函数一样去对他进行使用\n",
        "print(metric([0.], [1.])) # 输入是两个列表。真实列表和预测列表\n",
        "print(metric.result()) #keras里面的metric具有累加功能的，可以通过调用多次看下\n",
        "#这是metric的一个特性，就是它可以累加数据\n",
        "#如果不想累加呢，我们只需要调用metric.reset_states()就可以了\n",
        "#这样他就会把之前记录结果全部清空\n",
        "\n",
        "metric.reset_states()\n",
        "metric([1.], [3.])\n",
        "print(metric.result()) # 之前结果清空了\n",
        "#我们可以在每个epoch结束的时候调用下reset_states，然后再去统计在这里epoch内，训练集上面的结果"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(9.0, shape=(), dtype=float32)\n",
            "tf.Tensor(5.0, shape=(), dtype=float32)\n",
            "tf.Tensor(5.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmEu8OVAxdF",
        "colab_type": "code",
        "outputId": "58a33dea-c4b9-416c-e3fb-018b93333c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 需要改的就是model.fit部分，fit函数部分都做了什么呢？\n",
        "# 1. 按照batch的形式呢，去遍历训练集 ，在每一次初始化去训练的时候呢，都会得到一个指标，也就是loss. 然后是要统计metric\n",
        "#    1.1 在训练的时候呢，会自动求导，去更新参数。在这里我们想要替换的是这一部分，因为他是由一个fit函数去封装的，所以呢\n",
        "#      我们需要替换这一部分的话，这三部分都要自己实现\n",
        "# 2. 然后在一次所有batch训练完以后呢，相当于一次epoch结束，这时我们会去验证集进行验证，统计出在验证集的metric\n",
        "\n",
        "\n",
        "epochs = 100   #执行100次\n",
        "batch_size = 32\n",
        "steps_per_epoch = len(x_train_scaled) // batch_size #在每个epoch训练多少次\n",
        "optimizer = keras.optimizers.SGD()  #使用sgd,使用默认的learning_rate\n",
        "metric = keras.metrics.MeanSquaredError() #使用mse\n",
        "\n",
        "#如何去取数据呢，在fit函数里面呢，他应该是随机的去遍历数据，也就是我把数据随机的shuffle一次，然后呢从头到尾去遍历\n",
        "#这里呢，我们就使用一种更简洁的实现方法，去进行数据的遍历，他并不是严格的数据遍历，因为我们这里实现的方式呢，是\n",
        "#随机的去取，即我每次就从训练集里随机的取batch_size条样本就可以了\n",
        "def random_batch(x, y, batch_size=32):\n",
        "    idx = np.random.randint(0, len(x), size=batch_size) #先随机出来batch_size个索引，用numpy里面的random函数取出从最低值到最高值的32个数\n",
        "    #0是最小值，len(x)就是他的最大值，这是一个半闭半开区间，所以取出来的值不会超过len(x)\n",
        "    return x[idx], y[idx] #然后呢，在x和y上把索引对应的数据给返回出来就可以了，因为x和y都是numpy类型，所以可以这样取数据。idx其实是个列表\n",
        "\n",
        "#模型没变\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu',\n",
        "                       input_shape=x_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "#实现上面说的3步\n",
        "for epoch in range(epochs):  #遍历epochs\n",
        "    metric.reset_states()  #在每个epoch的开端呢，都要把metrics给reset下\n",
        "    for step in range(steps_per_epoch): # 在每个epoch里面，我都要循环steps_per_epoch次\n",
        "        x_batch, y_batch = random_batch(x_train_scaled, y_train, batch_size)\n",
        "        # 在每次进行训练的时候呢，我都要取出数据来，取出来batch_size个\n",
        "        # 然后再取出这些数据以后呢，我们就可以获取这些数据的预测值了\n",
        "\n",
        "        with tf.GradientTape() as tape: #求梯度需要打开一个tf.GradientTape()\n",
        "            y_pred = model(x_batch) #在这里呢，可以把model像函数一样使用，他的输入呢是x_batch，输出就是他的预测值\n",
        "            y_pred = tf.squeeze(y_pred, 1)\n",
        "            loss = keras.losses.mean_squared_error(y_batch, y_pred) #有了预测值以后就可以得到他的loss,这里使用mse\n",
        "            metric(y_batch, y_pred) #有了真实值和预测值，可以累计的去计算metric\n",
        "            #这里相当于我们的目标函数loss就setup好了，接下来我们去求梯度\n",
        "\n",
        "        grads = tape.gradient(loss, model.variables) #手动求梯度，参数是model的所有参数\n",
        "        grads_and_vars = zip(grads, model.variables) #把梯度和变量呢，一一绑定\n",
        "        optimizer.apply_gradients(grads_and_vars) #绑定以后，就可以像上个文件一样，optimizer.apply_gradients，去更新参数啦\n",
        "        print(\"\\rEpoch\", epoch, \" train mse:\",\n",
        "              metric.result().numpy(), end=\"\") #然后打印下，把训练的mse打印出来，他是一个训练的累计的值\n",
        "    y_valid_pred = model(x_valid_scaled) #在每个epoch训练完以后，就可以在验证机上进行验证啦，\n",
        "    y_valid_pred = tf.squeeze(y_valid_pred, 1) \n",
        "    valid_loss = keras.losses.mean_squared_error(y_valid_pred, y_valid)\n",
        "    print(\"\\t\", \"valid mse: \", valid_loss.numpy()) #在这里只用了一个loss\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "Epoch 0  train mse: 0.76856667\t valid mse:  0.6498970384363162\n",
            "Epoch 1  train mse: 0.7825577\t valid mse:  0.6805622780792883\n",
            "Epoch 2  train mse: 0.48554593\t valid mse:  0.48823736910830723\n",
            "Epoch 3  train mse: 0.45413145\t valid mse:  0.47299750216828235\n",
            "Epoch 4  train mse: 0.41907844\t valid mse:  0.4516531804336801\n",
            "Epoch 5  train mse: 0.43206713\t valid mse:  0.4353824332214284\n",
            "Epoch 6  train mse: 0.40812662\t valid mse:  0.4278446420896621\n",
            "Epoch 7  train mse: 0.39901805\t valid mse:  0.4231546313701608\n",
            "Epoch 8  train mse: 0.38326445\t valid mse:  0.4132924501046734\n",
            "Epoch 9  train mse: 0.66875666\t valid mse:  0.5106283670573705\n",
            "Epoch 10  train mse: 0.45630127\t valid mse:  0.4603723174451882\n",
            "Epoch 11  train mse: 0.43282712\t valid mse:  0.4379744532578509\n",
            "Epoch 12  train mse: 0.42354086\t valid mse:  0.4221945263659818\n",
            "Epoch 13  train mse: 0.4060955\t valid mse:  0.4179349549677343\n",
            "Epoch 14  train mse: 0.39214417\t valid mse:  0.40175765073835584\n",
            "Epoch 15  train mse: 0.4475403\t valid mse:  0.4247492372786958\n",
            "Epoch 16  train mse: 0.3948022\t valid mse:  0.4337294656123176\n",
            "Epoch 17  train mse: 0.43739015\t valid mse:  0.40158868641845624\n",
            "Epoch 18  train mse: 0.37759513\t valid mse:  0.39405314727220025\n",
            "Epoch 19  train mse: 0.3755379\t valid mse:  0.3903612306848661\n",
            "Epoch 20  train mse: 0.37158617\t valid mse:  0.3867771252648337\n",
            "Epoch 21  train mse: 0.37792927\t valid mse:  0.38555312066004765\n",
            "Epoch 22  train mse: 0.36343446\t valid mse:  0.4016111020296414\n",
            "Epoch 23  train mse: 0.3654477\t valid mse:  0.3813605055870822\n",
            "Epoch 24  train mse: 0.37500298\t valid mse:  0.38096737828321564\n",
            "Epoch 25  train mse: 0.3747957\t valid mse:  0.378170602705201\n",
            "Epoch 26  train mse: 0.36138642\t valid mse:  0.37818034372187137\n",
            "Epoch 27  train mse: 0.3623043\t valid mse:  0.3764811025108467\n",
            "Epoch 28  train mse: 0.3425968\t valid mse:  0.3759776711511447\n",
            "Epoch 29  train mse: 0.35471463\t valid mse:  0.37541490065356464\n",
            "Epoch 30  train mse: 0.35454953\t valid mse:  0.37768505010211567\n",
            "Epoch 31  train mse: 0.35376692\t valid mse:  0.3697601474609106\n",
            "Epoch 32  train mse: 0.34547248\t valid mse:  0.36833367051356525\n",
            "Epoch 33  train mse: 0.4663624\t valid mse:  0.5338755302540797\n",
            "Epoch 34  train mse: 0.36042166\t valid mse:  0.37379238385764607\n",
            "Epoch 35  train mse: 0.35364667\t valid mse:  0.37411293686917735\n",
            "Epoch 36  train mse: 0.36167005\t valid mse:  0.36661574002966885\n",
            "Epoch 37  train mse: 0.34932655\t valid mse:  0.3681758409486376\n",
            "Epoch 38  train mse: 0.3645213\t valid mse:  0.36242173806789346\n",
            "Epoch 39  train mse: 0.36499885\t valid mse:  0.3594083998008487\n",
            "Epoch 40  train mse: 0.3407667\t valid mse:  0.3640741344919864\n",
            "Epoch 41  train mse: 0.3496654\t valid mse:  0.36832450893419044\n",
            "Epoch 42  train mse: 0.34142357\t valid mse:  0.3571163331474005\n",
            "Epoch 43  train mse: 0.36482748\t valid mse:  0.42993945120614363\n",
            "Epoch 44  train mse: 0.34350434\t valid mse:  0.35813663348232583\n",
            "Epoch 45  train mse: 0.34483367\t valid mse:  0.36239072840679243\n",
            "Epoch 46  train mse: 0.35148028\t valid mse:  0.35333618376683146\n",
            "Epoch 47  train mse: 0.3276436\t valid mse:  0.36331222194580404\n",
            "Epoch 48  train mse: 0.33606696\t valid mse:  0.35449880018195706\n",
            "Epoch 49  train mse: 0.3501262\t valid mse:  0.36415620934952303\n",
            "Epoch 50  train mse: 0.3418193\t valid mse:  0.35529656504725077\n",
            "Epoch 51  train mse: 0.34139687\t valid mse:  0.3521544695364538\n",
            "Epoch 52  train mse: 0.32671726\t valid mse:  0.35145104947602496\n",
            "Epoch 53  train mse: 0.3290718\t valid mse:  0.3478780888309678\n",
            "Epoch 54  train mse: 0.33555707\t valid mse:  0.35153194276176525\n",
            "Epoch 55  train mse: 0.3495742\t valid mse:  0.3452403996977329\n",
            "Epoch 56  train mse: 0.33631456\t valid mse:  0.3520486977181664\n",
            "Epoch 57  train mse: 0.33705178\t valid mse:  0.3479417194785038\n",
            "Epoch 58  train mse: 0.32913324\t valid mse:  0.36760750321818114\n",
            "Epoch 59  train mse: 0.34600025\t valid mse:  0.3616914669201727\n",
            "Epoch 60  train mse: 0.34970576\t valid mse:  0.34908906495278896\n",
            "Epoch 61  train mse: 0.3288475\t valid mse:  0.34229828816070274\n",
            "Epoch 62  train mse: 0.31476608\t valid mse:  0.34383756783443475\n",
            "Epoch 63  train mse: 0.3219473\t valid mse:  0.5148017064582927\n",
            "Epoch 64  train mse: 0.38731092\t valid mse:  0.3471026829173202\n",
            "Epoch 65  train mse: 0.3249168\t valid mse:  0.34345382229522586\n",
            "Epoch 66  train mse: 0.32063806\t valid mse:  0.349404971651654\n",
            "Epoch 67  train mse: 0.3321009\t valid mse:  0.3500567264699561\n",
            "Epoch 68  train mse: 0.31849277\t valid mse:  0.3397986480160588\n",
            "Epoch 69  train mse: 0.33124813\t valid mse:  0.3837357397648264\n",
            "Epoch 70  train mse: 0.3365355\t valid mse:  0.34145619965405005\n",
            "Epoch 71  train mse: 0.3210983\t valid mse:  0.3408842546579242\n",
            "Epoch 72  train mse: 0.32567284\t valid mse:  0.3348532357729297\n",
            "Epoch 73  train mse: 0.3276091\t valid mse:  0.33786056702525724\n",
            "Epoch 74  train mse: 0.32377008\t valid mse:  0.33729326364781315\n",
            "Epoch 75  train mse: 0.32901517\t valid mse:  0.3336957092078385\n",
            "Epoch 76  train mse: 0.3146349\t valid mse:  0.34064533480575615\n",
            "Epoch 77  train mse: 0.32181737\t valid mse:  0.33288510379706787\n",
            "Epoch 78  train mse: 0.3183826\t valid mse:  0.33362015696780783\n",
            "Epoch 79  train mse: 0.3243395\t valid mse:  0.3296645474919008\n",
            "Epoch 80  train mse: 0.32511094\t valid mse:  0.3286619386840709\n",
            "Epoch 81  train mse: 0.31283027\t valid mse:  0.3331615230448342\n",
            "Epoch 82  train mse: 0.31011227\t valid mse:  0.32834953776989134\n",
            "Epoch 83  train mse: 0.3215455\t valid mse:  0.3304943698594298\n",
            "Epoch 84  train mse: 0.32012647\t valid mse:  0.3373142389631974\n",
            "Epoch 85  train mse: 0.32725206\t valid mse:  0.3303822310326022\n",
            "Epoch 86  train mse: 0.31639075\t valid mse:  0.3291142863135633\n",
            "Epoch 87  train mse: 0.3097541\t valid mse:  0.34516178924939045\n",
            "Epoch 88  train mse: 0.32214913\t valid mse:  0.3254956823462852\n",
            "Epoch 89  train mse: 0.32683244\t valid mse:  0.32444628215496674\n",
            "Epoch 90  train mse: 0.2986637\t valid mse:  0.3308206227408807\n",
            "Epoch 91  train mse: 0.31148574\t valid mse:  0.32409915822967256\n",
            "Epoch 92  train mse: 0.30744103\t valid mse:  0.3251946452186341\n",
            "Epoch 93  train mse: 0.3153383\t valid mse:  0.32693692770076166\n",
            "Epoch 94  train mse: 0.30395845\t valid mse:  0.32700339300359915\n",
            "Epoch 95  train mse: 0.31347698\t valid mse:  0.3304036553202633\n",
            "Epoch 96  train mse: 0.2963186\t valid mse:  0.32528846451761023\n",
            "Epoch 97  train mse: 0.31675828\t valid mse:  0.32619809038421815\n",
            "Epoch 98  train mse: 0.3093993\t valid mse:  0.3255655338549605\n",
            "Epoch 99  train mse: 0.31722888\t valid mse:  0.32479421410311965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzZLfgJeAxdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}