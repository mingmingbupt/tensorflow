{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf_keras_to_estimator.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf_keras_to_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC7tOoZL9s64",
        "colab_type": "code",
        "outputId": "fc8a6701-8029-4333-8a06-131020b167a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 1.0.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 2.2.0-rc2\n",
            "tensorflow.keras 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmOI64Zy-bgP",
        "colab_type": "code",
        "outputId": "0326eb20-9b0e-463e-bdd2-69e3934f738a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "#如何在colab上使用在google cloud上面的文件\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/tensorflow/Tensorflow2.0--rumendaoshijian/chapter_5\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf_premade_estimators-new_feature.ipynb',\n",
              " 'tf_premade_estimators.ipynb',\n",
              " 'data',\n",
              " 'tf_keras_to_estimator.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yz6VdfH9s68",
        "colab_type": "code",
        "outputId": "f1086b69-5488-4d8b-bea4-01c27a2990d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
        "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
        "train_file = \"./data/titanic/train.csv\" #这里把缺失值做了填充 训练集\n",
        "eval_file = \"./data/titanic/eval.csv\" #这里把缺失值做了填充  测试集\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "eval_df = pd.read_csv(eval_file)\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  22.0  ...  unknown  Southampton      n\n",
            "1         1  female  38.0  ...        C    Cherbourg      n\n",
            "2         1  female  26.0  ...  unknown  Southampton      y\n",
            "3         1  female  35.0  ...        C  Southampton      n\n",
            "4         0    male  28.0  ...  unknown   Queenstown      y\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  35.0  ...  unknown  Southampton      y\n",
            "1         0    male  54.0  ...        E  Southampton      y\n",
            "2         1  female  58.0  ...        C  Southampton      y\n",
            "3         1  female  55.0  ...  unknown  Southampton      y\n",
            "4         1    male  34.0  ...        D  Southampton      y\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLD9kH0k9s6_",
        "colab_type": "code",
        "outputId": "45c41ba6-a901-40d8-9259-0cddebefc260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "y_train = train_df.pop('survived') #因为survived是我们预测的值，是y，要取出来，同时在train_df里去掉\n",
        "y_eval = eval_df.pop('survived')\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())\n",
        "print(y_train.head())\n",
        "print(y_eval.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      sex   age  n_siblings_spouses  parch  ...  class     deck  embark_town alone\n",
            "0    male  22.0                   1      0  ...  Third  unknown  Southampton     n\n",
            "1  female  38.0                   1      0  ...  First        C    Cherbourg     n\n",
            "2  female  26.0                   0      0  ...  Third  unknown  Southampton     y\n",
            "3  female  35.0                   1      0  ...  First        C  Southampton     n\n",
            "4    male  28.0                   0      0  ...  Third  unknown   Queenstown     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "      sex   age  n_siblings_spouses  parch  ...   class     deck  embark_town alone\n",
            "0    male  35.0                   0      0  ...   Third  unknown  Southampton     y\n",
            "1    male  54.0                   0      0  ...   First        E  Southampton     y\n",
            "2  female  58.0                   0      0  ...   First        C  Southampton     y\n",
            "3  female  55.0                   0      0  ...  Second  unknown  Southampton     y\n",
            "4    male  34.0                   0      0  ...  Second        D  Southampton     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBAHHjDW9s7B",
        "colab_type": "code",
        "outputId": "3fd7a845-d063-4708-d6ba-b2253328b5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "train_df.describe() #看下数据集里面的统计量，因为只有这四个是数值的，其他都是离散型的"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qv7RhBc9s7E",
        "colab_type": "code",
        "outputId": "93618a1b-8912-401f-ec0f-1cb46c569e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_df.shape, eval_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(627, 9) (264, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4e7bxId9s7G",
        "colab_type": "code",
        "outputId": "615e4172-eb60-41d4-e833-688a8e62a2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "train_df.age.hist(bins = 20) #年龄分布，bins就是我把所有值分成多少份"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c96e61390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWskMwV9s7J",
        "colab_type": "code",
        "outputId": "966169ab-2b22-4aed-8f97-2d7175e491d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "train_df.sex.value_counts().plot(kind = 'barh') #不同性别的人各占多少，画个柱状图，画一个横向的柱状图，横向就是kind=barh，纵向就是kind=barv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c9690d518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMdUlEQVR4nO3cf4xld1nH8c8D225NS4rQhmxacChu\nJKRAW0tFRQKICF1DQTAhEigJoVEUNabRIpHUVLSCKJqgpCgWFQVBDAghiLTGBLF11/7Y1nah2jVS\nKw0SlpomVenXP+5ZmGec2XbbmXtmy+uVTPbcc+/e88x3cve959y7W2OMAMBhj5h7AAC2F2EAoBEG\nABphAKARBgCaHXMPsBlOOeWUsbKyMvcYAMeUffv2fWmMcera/Q+LMKysrGTv3r1zjwFwTKmqf11v\nv0tJADTCAEAjDAA0wgBAIwwANMIAQCMMADTCAEAjDAA0wgBAIwwANMIAQCMMADTCAEAjDAA0wgBA\nIwwANMIAQCMMADTCAEAjDAA0wgBAIwwANMIAQCMMADTCAECzY+4BNsP+Ow5l5ZKPzz0GrOvg5Xvm\nHgGOijMGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAa\nYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAmvsNQ1X9VFXdUlXv24oBqurSqrp4K54bgKO34wE8\n5vVJnj/G+MJWDwPA/I4Yhqp6V5Izknyiqt6f5ElJzkxyXJJLxxgfqarXJHlJkhOT7E7y60mOT/Kq\nJPcmOX+M8eWqel2Si6b7bkvyqjHGPWuO96Qk70xyapJ7krxujHHrJn2vADwAR7yUNMb4sST/nuS5\nWfzBf9UY47zp9tuq6sTpoWcm+eEkz0jyliT3jDHOTvLZJK+eHvPhMcYzxhhPT3JLkteuc8grkrxh\njPGdSS5O8jsbzVZVF1XV3qra+7V7Dj2w7xaA+/VALiUd9oIkL171fsAJSZ4wbV89xrg7yd1VdSjJ\nX0779yd52rR9ZlX9cpJHJzkpySdXP3lVnZTke5J8sKoO79650TBjjCuyCEl27to9juL7AOAIjiYM\nleRlY4wDbWfVd2Vxyeiw+1bdvm/VMa5M8pIxxg3T5afnrHn+RyT5yhjjrKOYCYBNdjQfV/1kkjfU\n9Nf5qjr7KI/1qCR3VtVxSV659s4xxleT3F5VPzI9f1XV04/yGAA8REcThsuyeNP5xqq6ebp9NH4x\nyTVJPpNkozeUX5nktVV1Q5Kbk1xwlMcA4CGqMY79y/M7d+0euy58x9xjwLoOXr5n7hFgXVW1b4xx\n7tr9/uUzAI0wANAIAwCNMADQCAMAjTAA0AgDAI0wANAIAwCNMADQCAMAjTAA0AgDAI0wANAIAwCN\nMADQCAMAjTAA0AgDAI0wANAIAwDNjrkH2AxPPe3k7L18z9xjADwsOGMAoBEGABphAKARBgAaYQCg\nEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKAR\nBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEG\nABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCgEQYAGmEAoBEGABphAKARBgAaYQCg2TH3\nAJth/x2HsnLJx+ceA2CpDl6+Z0ue1xkDAI0wANAIAwCNMADQCAMAjTAA0AgDAI0wANAIAwCNMADQ\nCAMAjTAA0AgDAI0wANAIAwCNMADQCAMAjTAA0AgDAI0wANAIAwCNMADQCAMAzbYIQ1U9p6o+Nvcc\nAGyTMACwfWxaGKpqpapuraorq+pzVfW+qnp+VX2mqj5fVedNX5+tquuq6u+q6jvWeZ4Tq+o9VXXt\n9LgLNmtGAO7fZp8xfHuStyd58vT1o0meleTiJL+Q5NYk3zfGODvJm5P8yjrP8aYkV40xzkvy3CRv\nq6oT1z6oqi6qqr1Vtfdr9xza5G8D4JvXjk1+vtvHGPuTpKpuTvLpMcaoqv1JVpKcnOS9VbU7yUhy\n3DrP8YIkL66qi6fbJyR5QpJbVj9ojHFFkiuSZOeu3WOTvw+Ab1qbHYZ7V23ft+r2fdOxLkty9Rjj\npVW1kuRv1nmOSvKyMcaBTZ4NgAdg2W8+n5zkjmn7NRs85pNJ3lBVlSRVdfYS5gJgsuwwvDXJr1bV\nddn4bOWyLC4x3ThdjrpsWcMBkNQYx/7l+Z27do9dF75j7jEAlurg5Xse0u+vqn1jjHPX7vfvGABo\nhAGARhgAaIQBgEYYAGiEAYBGGABohAGARhgAaIQBgEYYAGiEAYBGGABohAGARhgAaIQBgEYYAGiE\nAYBGGABohAGARhgAaIQBgGbH3ANshqeednL2Xr5n7jEAHhacMQDQCAMAjTAA0AgDAI0wANAIAwCN\nMADQCAMAjTAA0AgDAI0wANAIAwCNMADQCAMAjTAA0AgDAI0wANAIAwCNMADQCAMAjTAA0AgDAI0w\nANAIAwCNMADQCAMATY0x5p7hIauqu5McmHuODZyS5EtzD7GO7TpXYrYHy2wPzjfzbN82xjh17c4d\nW3jAZTowxjh37iHWU1V7t+Ns23WuxGwPltkeHLP9fy4lAdAIAwDNwyUMV8w9wBFs19m261yJ2R4s\nsz04ZlvjYfHmMwCb5+FyxgDAJhEGAJpjOgxV9cKqOlBVt1XVJdtgnoNVtb+qrq+qvdO+x1TVp6rq\n89Ov37qkWd5TVXdV1U2r9q07Sy389rSON1bVOTPMdmlV3TGt3fVVdf6q+944zXagqn5wi2d7fFVd\nXVX/VFU3V9VPT/tnXbsjzDX7ulXVCVV1bVXdMM32S9P+J1bVNdMMH6iq46f9O6fbt033r8ww25VV\ndfuqdTtr2r/U18J0zEdW1XVV9bHp9uzrljHGMfmV5JFJ/jnJGUmOT3JDkqfMPNPBJKes2ffWJJdM\n25ck+bUlzfLsJOckuen+ZklyfpJPJKkkz0xyzQyzXZrk4nUe+5TpZ7szyROnn/kjt3C2XUnOmbYf\nleRz0wyzrt0R5pp93abv/aRp+7gk10xr8WdJXjHtf1eSH5+2X5/kXdP2K5J8YAt/nhvNdmWSl6/z\n+KW+FqZj/mySP0nysen27Ot2LJ8xnJfktjHGv4wx/jvJ+5NcMPNM67kgyXun7fcmeckyDjrG+Nsk\nX36As1yQ5A/Hwt8neXRV7VrybBu5IMn7xxj3jjFuT3JbFj/7rZrtzjHGP07bdye5JclpmXntjjDX\nRpa2btP3/l/TzeOmr5HkeUk+NO1fu2aH1/JDSb6/qmrJs21kqa+Fqjo9yZ4kvzfdrmyDdTuWw3Ba\nkn9bdfsLOfILZRlGkr+qqn1VddG073FjjDun7f9I8rh5RjviLNtlLX9yOn1/z6pLbrPNNp2qn53F\n3zK3zdqtmSvZBus2XQ65PsldST6VxRnKV8YY/7vO8b8+23T/oSSPXdZsY4zD6/aWad1+s6p2rp1t\nnbm3wjuS/FyS+6bbj802WLdjOQzb0bPGGOckeVGSn6iqZ6++cyzOAbfF54O30yyT303ypCRnJbkz\nydvnHKaqTkry50l+Zozx1dX3zbl268y1LdZtjPG1McZZSU7P4szkyXPMsZ61s1XVmUnemMWMz0jy\nmCQ/v+y5quqHktw1xti37GPfn2M5DHckefyq26dP+2Yzxrhj+vWuJH+RxQvki4dPRadf75pvwg1n\nmX0txxhfnF7A9yV5d75x2WPps1XVcVn84fu+McaHp92zr916c22ndZvm+UqSq5N8dxaXYQ7/f2yr\nj//12ab7T07yn0uc7YXTpbkxxrg3yR9knnX73iQvrqqDWVwKf16S38o2WLdjOQz/kGT39A7+8Vm8\nGfPRuYapqhOr6lGHt5O8IMlN00wXTg+7MMlH5pkwOcIsH03y6ukTGc9McmjVZZOlWHMd96VZrN3h\n2V4xfSLjiUl2J7l2C+eoJL+f5JYxxm+sumvWtdtoru2wblV1alU9etr+liQ/kMV7IFcnefn0sLVr\ndngtX57kquksbFmz3boq8pXFNfzV67aU18IY441jjNPHGCtZ/Pl11RjjldkG67al77Zv9VcWnyD4\nXBbXM9808yxnZPEpkBuS3Hx4niyuAX46yeeT/HWSxyxpnj/N4tLC/2RxnfK1G82SxScw3jmt4/4k\n584w2x9Nx74xixfArlWPf9M024EkL9ri2Z6VxWWiG5NcP32dP/faHWGu2dctydOSXDfNcFOSN696\nTVybxRvfH0yyc9p/wnT7tun+M2aY7app3W5K8sf5xieXlvpaWDXnc/KNTyXNvm7+SwwAmmP5UhIA\nW0AYAGiEAYBGGABohAGARhgAaIQBgOb/AEYEJAUZdZ+FAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YnFHJeN9s7L",
        "colab_type": "code",
        "outputId": "ea14729b-e364-4c70-abea-9a095763b98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "train_df['class'].value_counts().plot(kind = 'barh') #统计下不同仓位的乘客各有多少 #这里为什么用train_df['class']，\n",
        "#而不是train_df.class呢，因为class跟dataframe的自带的函数冲突了，所以只能用这种方式来取数据了"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c968995c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU+he/vp3xQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nwF-whB9s7O",
        "colab_type": "code",
        "outputId": "a01ad253-01e5-4750-863b-e93f739ff095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind='barh') #男性中有多少获救了 女性中有多少获救了"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c967f4b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD4CAYAAAAkRnsLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2xuCsrd9s7Q",
        "colab_type": "code",
        "outputId": "d0bf9cbf-f2bb-4e93-9510-e561e7c7353d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# 使用feature_columns对数据进行封装\n",
        "# feature_columns是专门针对列数据做封装的一种数据表达手法，如果列是离散值，可以很方便做onehoet编码\n",
        "# 如果列是连续值，也很方便的做分桶，变成离散特征，如果需要的话\n",
        "\n",
        "# 把特征分成两类特征，离散特征和连续特征\n",
        "# 离散特征做onehot编码变成一个向量\n",
        "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "\n",
        "#可以直接输入，也可以分桶，也可以做其他变换比如scaling\n",
        "numeric_columns = ['age', 'fare']\n",
        "\n",
        "feature_columns = [] #定义一个feature_column列表\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique() #获取这个离散特征所有可能的值\n",
        "    print(categorical_column, vocab)\n",
        "    #离散特征做onehot编码\n",
        "    feature_columns.append(\n",
        "        #做onehot编码需要调用tf.feature_column.indicator_column来实现\n",
        "        #大家注意，feature_column下面的这些东西是可以嵌套的，做一个嵌套就是做一个处理\n",
        "        tf.feature_column.indicator_column(\n",
        "            #先定义一个feature_column\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list( \n",
        "                #tf.feature_column.categorical_column_with_vocabulary_list这个函数有两个参数\n",
        "                categorical_column, vocab)))\n",
        "\n",
        "for categorical_column in numeric_columns: #连续特征直接作为输入，直接用tf.feature_column.numeric_column\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.numeric_column(\n",
        "            categorical_column, dtype=tf.float32))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male' 'female']\n",
            "n_siblings_spouses [1 0 3 4 2 5 8]\n",
            "parch [0 1 2 5 3 4]\n",
            "class ['Third' 'First' 'Second']\n",
            "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
            "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
            "alone ['n' 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTS5jh5AWCAp",
        "colab_type": "code",
        "outputId": "ec1ec338-55f6-4909-faac-6b938f2e93d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dict(train_df) #key 就是列名 value就是它的数据值"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 0      22.0\n",
              " 1      38.0\n",
              " 2      26.0\n",
              " 3      35.0\n",
              " 4      28.0\n",
              "        ... \n",
              " 622    28.0\n",
              " 623    25.0\n",
              " 624    19.0\n",
              " 625    28.0\n",
              " 626    32.0\n",
              " Name: age, Length: 627, dtype: float64, 'alone': 0      n\n",
              " 1      n\n",
              " 2      y\n",
              " 3      n\n",
              " 4      y\n",
              "       ..\n",
              " 622    y\n",
              " 623    y\n",
              " 624    y\n",
              " 625    n\n",
              " 626    y\n",
              " Name: alone, Length: 627, dtype: object, 'class': 0       Third\n",
              " 1       First\n",
              " 2       Third\n",
              " 3       First\n",
              " 4       Third\n",
              "         ...  \n",
              " 622    Second\n",
              " 623     Third\n",
              " 624     First\n",
              " 625     Third\n",
              " 626     Third\n",
              " Name: class, Length: 627, dtype: object, 'deck': 0      unknown\n",
              " 1            C\n",
              " 2      unknown\n",
              " 3            C\n",
              " 4      unknown\n",
              "         ...   \n",
              " 622    unknown\n",
              " 623    unknown\n",
              " 624          B\n",
              " 625    unknown\n",
              " 626    unknown\n",
              " Name: deck, Length: 627, dtype: object, 'embark_town': 0      Southampton\n",
              " 1        Cherbourg\n",
              " 2      Southampton\n",
              " 3      Southampton\n",
              " 4       Queenstown\n",
              "           ...     \n",
              " 622    Southampton\n",
              " 623    Southampton\n",
              " 624    Southampton\n",
              " 625    Southampton\n",
              " 626     Queenstown\n",
              " Name: embark_town, Length: 627, dtype: object, 'fare': 0       7.2500\n",
              " 1      71.2833\n",
              " 2       7.9250\n",
              " 3      53.1000\n",
              " 4       8.4583\n",
              "         ...   \n",
              " 622    10.5000\n",
              " 623     7.0500\n",
              " 624    30.0000\n",
              " 625    23.4500\n",
              " 626     7.7500\n",
              " Name: fare, Length: 627, dtype: float64, 'n_siblings_spouses': 0      1\n",
              " 1      1\n",
              " 2      0\n",
              " 3      1\n",
              " 4      0\n",
              "       ..\n",
              " 622    0\n",
              " 623    0\n",
              " 624    0\n",
              " 625    1\n",
              " 626    0\n",
              " Name: n_siblings_spouses, Length: 627, dtype: int64, 'parch': 0      0\n",
              " 1      0\n",
              " 2      0\n",
              " 3      0\n",
              " 4      0\n",
              "       ..\n",
              " 622    0\n",
              " 623    0\n",
              " 624    0\n",
              " 625    2\n",
              " 626    0\n",
              " Name: parch, Length: 627, dtype: int64, 'sex': 0        male\n",
              " 1      female\n",
              " 2      female\n",
              " 3      female\n",
              " 4        male\n",
              "         ...  \n",
              " 622      male\n",
              " 623      male\n",
              " 624    female\n",
              " 625    female\n",
              " 626      male\n",
              " Name: sex, Length: 627, dtype: object}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UflXK9249s7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构建dataset\n",
        "#参数为 x y epoch 是否需要混排 batchsize\n",
        "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
        "                 batch_size = 32):\n",
        "    #构建数据集\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(data_df), label_df)) #data_df是一个多列的pandas的dataframe结构\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000) #buffersize=10000\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset #返回x y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ddDKA-9s7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = make_dataset(train_df, y_train, batch_size = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIymwU_K9s7X",
        "colab_type": "code",
        "outputId": "0a3ebfca-d021-4079-f6ca-d521550ca0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "for x, y in train_dataset.take(1):\n",
        "    print(x, y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'female'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28., 29., 45., 39., 28.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 0, 0, 1])>, 'parch': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 0, 0])>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([ 7.8958, 66.6   , 35.5   ,  7.925 , 82.1708])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'First', b'First', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'C', b'unknown', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
            "array([b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
            "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'y', b'n'], dtype=object)>} tf.Tensor([0 0 0 1 1], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQenbr19s7Z",
        "colab_type": "code",
        "outputId": "b78cda97-ae82-403d-96a7-ba5ce3585f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "#feature column和dataset结合使用\n",
        "# 在这里把他们联合起来的API呢是keras.layers.DenseFeature\n",
        "# 这个keras.layers.DenseFeature可以把我们定义的feature_columns呢应用到dataset上去\n",
        "# feature_columns呢本质上是一组对feature进行变换的规则，\n",
        "#然后DenseFeature呢可以把这个规则应用到dataset的每一个数据上去\n",
        "for x, y in train_dataset.take(1):\n",
        "    age_column = feature_columns[7] #取出来age对应的feature_column\n",
        "    gender_column = feature_columns[0] #再取出gender对应的feature_column\n",
        "    #如何使用DenseFeatures把我们这个feature_column对应的规则应用到x上去\n",
        "    print(\"x=\",x)\n",
        "    print(keras.layers.DenseFeatures(age_column)(x).numpy()) #直接调用keras.layers.DenseFeatures\n",
        "    #参数是age_column,也就是我现在的DenseFeature现在只有age_column一个规则，然后我把它应用到x上去，然后我再取出它的numpy的值，然后打印出来\n",
        "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())#同理呢我再把DenseFeatures用gender_column来初始化，来应用到我们的x上"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x= {'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'female', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28., 34., 33.,  5., 36.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 1, 0, 0])>, 'parch': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 1, 0, 1])>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([  7.2292,  13.    ,  20.525 ,  12.475 , 512.3292])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'Second', b'Third', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'B'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
            "array([b'Cherbourg', b'Southampton', b'Southampton', b'Southampton',\n",
            "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'y', b'n', b'y', b'n'], dtype=object)>}\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "[[28.]\n",
            " [34.]\n",
            " [33.]\n",
            " [ 5.]\n",
            " [36.]]\n",
            "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B291NnhP9s7b",
        "colab_type": "code",
        "outputId": "f831b1a0-c2fc-43ad-ea73-6df365b64d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "# keras.layers.DenseFeature\n",
        "# 做一个全部的，也就是我们把feature_coloumns做为参数传给这个DenseFeatures\n",
        "for x, y in train_dataset.take(1):\n",
        "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "[[28.      0.      1.      0.      1.      0.      0.      0.      0.\n",
            "   1.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "  26.      0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]\n",
            " [34.      0.      1.      0.      0.      1.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "  13.      0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]\n",
            " [30.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "   7.8958  0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]\n",
            " [42.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "   7.55    0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]\n",
            " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
            "   7.75    0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnsl9OdG9s7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构建keras模型\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.DenseFeatures(feature_columns),#第一层变成DenseFeatures\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='softmax'),\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.SGD(lr=0.01),\n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4qEdhVg9s7f",
        "colab_type": "code",
        "outputId": "a00417c1-a783-4c16-e345-44b9e8a46fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 模型定义好以后有两种方式\n",
        "# 1. model.fit \n",
        "# 2. model -> estimator -> train把model转成estimator,然后再用estimator去训练模型\n",
        "\n",
        "train_dataset = make_dataset(train_df, y_train, epochs = 100) #初始化训练集dataset\n",
        "eval_dataset = make_dataset(eval_df, y_eval, epochs = 1, shuffle = False) #生成验证的dataset\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data = eval_dataset,\n",
        "                    steps_per_epoch = 20, #训练集样本数//batch_size\n",
        "                    validation_steps = 8, #验证机数量//batch_size\n",
        "                    epochs = 100) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layer dense_features_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 2.5663 - accuracy: 0.5750 - val_loss: 0.6339 - val_accuracy: 0.6836\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7834 - accuracy: 0.6531 - val_loss: 0.6339 - val_accuracy: 0.6562\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.6359 - val_loss: 0.7151 - val_accuracy: 0.6172\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6766 - val_loss: 0.6043 - val_accuracy: 0.6758\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6594 - val_loss: 0.5818 - val_accuracy: 0.6992\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6641 - val_loss: 0.5982 - val_accuracy: 0.6211\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.6766 - val_loss: 0.6513 - val_accuracy: 0.6055\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6781 - val_loss: 0.5995 - val_accuracy: 0.6836\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.6906 - val_loss: 0.5730 - val_accuracy: 0.7070\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6797 - val_loss: 0.5770 - val_accuracy: 0.7148\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7016 - val_loss: 0.5976 - val_accuracy: 0.6445\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7078 - val_loss: 0.5664 - val_accuracy: 0.7188\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7391 - val_loss: 0.5725 - val_accuracy: 0.6953\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6859 - val_loss: 0.5753 - val_accuracy: 0.7109\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7031 - val_loss: 0.5666 - val_accuracy: 0.7031\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7188 - val_loss: 0.5620 - val_accuracy: 0.6797\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7016 - val_loss: 0.6061 - val_accuracy: 0.6758\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7000 - val_loss: 0.5685 - val_accuracy: 0.6836\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7047 - val_loss: 0.5647 - val_accuracy: 0.6992\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7016 - val_loss: 0.5768 - val_accuracy: 0.6523\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6859 - val_loss: 0.5593 - val_accuracy: 0.6875\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7203 - val_loss: 0.5504 - val_accuracy: 0.6797\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.6922 - val_loss: 0.5543 - val_accuracy: 0.6953\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6812 - val_loss: 0.5596 - val_accuracy: 0.6992\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7312 - val_loss: 0.6574 - val_accuracy: 0.6406\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.6859 - val_loss: 0.5535 - val_accuracy: 0.7266\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6969 - val_loss: 0.5592 - val_accuracy: 0.6953\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7109 - val_loss: 0.5424 - val_accuracy: 0.6953\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7422 - val_loss: 0.5483 - val_accuracy: 0.6992\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7250 - val_loss: 0.6171 - val_accuracy: 0.6914\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7156 - val_loss: 0.5319 - val_accuracy: 0.7305\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7437 - val_loss: 0.5769 - val_accuracy: 0.6914\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7141 - val_loss: 0.5300 - val_accuracy: 0.7031\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7219 - val_loss: 0.5423 - val_accuracy: 0.7227\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7422 - val_loss: 0.5314 - val_accuracy: 0.7305\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7141 - val_loss: 0.5695 - val_accuracy: 0.6914\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7281 - val_loss: 0.6391 - val_accuracy: 0.6875\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7266 - val_loss: 0.5663 - val_accuracy: 0.7109\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7312 - val_loss: 0.5419 - val_accuracy: 0.7109\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7297 - val_loss: 0.5262 - val_accuracy: 0.7227\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7422 - val_loss: 0.5320 - val_accuracy: 0.7148\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7359 - val_loss: 0.5300 - val_accuracy: 0.7461\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7703 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7312 - val_loss: 0.5599 - val_accuracy: 0.6992\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7172 - val_loss: 0.5557 - val_accuracy: 0.7070\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7453 - val_loss: 0.5199 - val_accuracy: 0.7305\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7359 - val_loss: 0.5334 - val_accuracy: 0.6992\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7484 - val_loss: 0.5125 - val_accuracy: 0.7539\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7344 - val_loss: 0.5126 - val_accuracy: 0.7383\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7312 - val_loss: 0.5219 - val_accuracy: 0.7305\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7281 - val_loss: 0.6161 - val_accuracy: 0.6953\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7391 - val_loss: 0.5179 - val_accuracy: 0.7266\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7531 - val_loss: 0.5236 - val_accuracy: 0.7578\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7453 - val_loss: 0.5379 - val_accuracy: 0.7305\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6953 - val_loss: 0.5243 - val_accuracy: 0.7227\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7422 - val_loss: 0.5613 - val_accuracy: 0.6641\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7125 - val_loss: 0.5428 - val_accuracy: 0.7227\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7234 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7422 - val_loss: 0.5240 - val_accuracy: 0.7383\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7406 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7656 - val_loss: 0.5269 - val_accuracy: 0.7148\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7453 - val_loss: 0.5059 - val_accuracy: 0.7617\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7797 - val_loss: 0.5902 - val_accuracy: 0.7148\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7250 - val_loss: 0.5646 - val_accuracy: 0.6953\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7203 - val_loss: 0.5257 - val_accuracy: 0.7266\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7641 - val_loss: 0.5179 - val_accuracy: 0.7305\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7437 - val_loss: 0.5339 - val_accuracy: 0.7266\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7297 - val_loss: 0.5027 - val_accuracy: 0.7617\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7766 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7328 - val_loss: 0.5434 - val_accuracy: 0.7344\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7547 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7250 - val_loss: 0.7479 - val_accuracy: 0.5117\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7312 - val_loss: 0.4988 - val_accuracy: 0.7734\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7547 - val_loss: 0.5110 - val_accuracy: 0.7539\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7828 - val_loss: 0.5197 - val_accuracy: 0.7266\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7453 - val_loss: 0.5991 - val_accuracy: 0.6680\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7422 - val_loss: 0.5282 - val_accuracy: 0.7305\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7344 - val_loss: 0.5536 - val_accuracy: 0.7266\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7625 - val_loss: 0.5479 - val_accuracy: 0.7266\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7766 - val_loss: 0.5114 - val_accuracy: 0.7383\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7625 - val_loss: 0.5032 - val_accuracy: 0.7266\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7469 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7656 - val_loss: 0.5952 - val_accuracy: 0.6914\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7500 - val_loss: 0.5269 - val_accuracy: 0.7266\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7750 - val_loss: 0.5009 - val_accuracy: 0.7383\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7641 - val_loss: 0.4922 - val_accuracy: 0.7422\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7516 - val_loss: 0.5274 - val_accuracy: 0.7148\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7703 - val_loss: 0.4994 - val_accuracy: 0.7461\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7781 - val_loss: 0.5059 - val_accuracy: 0.7617\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7563 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7578 - val_loss: 0.5110 - val_accuracy: 0.7305\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7594 - val_loss: 0.4994 - val_accuracy: 0.7422\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7484 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7719 - val_loss: 0.9362 - val_accuracy: 0.4766\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7688 - val_loss: 0.5517 - val_accuracy: 0.7227\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7625 - val_loss: 0.6256 - val_accuracy: 0.7070\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7641 - val_loss: 0.6168 - val_accuracy: 0.7031\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7629 - val_loss: 0.5141 - val_accuracy: 0.7578\n",
            "Epoch 99/100\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-165a8ce313b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#训练集样本数//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#验证机数量//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     epochs = 100) \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_finalize_progbar\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    933\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEnq1VA9s7h",
        "colab_type": "code",
        "outputId": "7118f637-30d8-4b8d-e4d4-9ceda77ed273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 2.使用第二种方法将keras转成estimator进行训练\n",
        "estimator = keras.estimator.model_to_estimator(model) #调用keras.estimator.model_to_estimator将keras转成estimator\n",
        "# 1. function\n",
        "# 2. return a. (features, labels) b. dataset -> (feature, label)\n",
        "estimator.train(input_fn = lambda : make_dataset(\n",
        "    train_df, y_train, epochs=100)) #在estimator里如何训练呢，input_fn是一个函数，可以是具体函数，也可以是lambda匿名函数，\n",
        "    #input_fn返回的结果呢，必须是以下几种\n",
        "    # 1 (features, labels)组成的元组，这里面features,lables可以是列表，也可以是numpy数组等等\n",
        "    # 2. 可以是dataset,dataset里面的数据呢，必须是(feature, label)\n",
        "    # 这就是input_fn的要求\n",
        "    # 之前我们定义了一个make_dataset,这个make_dataset就能够返回这样一个dataset.它里面的值就是featur和label\n",
        "    # 但是make_dataset是有参数的，而我们input_fn是要求没有参数的，所以我们使用一个lambda表达式对这个make_dataset做一个封装\n",
        "    # 让他变成没有参数的函数\n",
        "\n",
        "#得到了一个错误，错误提示 数据中的case和我期望的case不一样，我期望得到的case是input_3, input_9, input_6等等\n",
        "#这个期望得到的case是什么，是我们在定义model的时候这个feature_columns.而我们知道，在我们的feature_columns里面\n",
        "#他们都是一些具体的值，比方说age，gender等等，但是他在这里却把这些值变成了input_3, input_2, input_9等等\n",
        "#所以说呢，他里面真正feature_columns的名字呢没有被保存下来，而我们数据中呢，则是真正的column的名字，这里不匹配，这也是\n",
        "#tensorflow2.0的bug 这是tensorflow框架的bug\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl75nx6es\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
            "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl75nx6es', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0f8b3c62be92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. return a. (features, labels) b. dataset -> (feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m estimator.train(input_fn = lambda : make_dataset(\n\u001b[0m\u001b[1;32m      5\u001b[0m     train_df, y_train, epochs=100)) #在estimator里如何训练呢，input_fn是一个函数，可以是具体函数，也可以是lambda匿名函数，\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#input_fn返回的结果呢，必须是以下几种\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0;32m-> 1211\u001b[0;31m                                            self.config)\n\u001b[0m\u001b[1;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    422\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 424\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    425\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     return _clone_functional_model(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                      sparse_tensor.SparseTensor, ragged_tensor.RaggedTensor)):\n\u001b[1;32m   1019\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m-> 1020\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m   1021\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q72TQsDZ9s7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}