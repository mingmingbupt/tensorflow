{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf-tfrecord_basic_api.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf_tfrecord_basic_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DK-nN9eG7Ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "cf1ea6c7-1a76-41b1-c4f5-bff6ab11b5cd"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 1.0.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 2.2.0-rc2\n",
            "tensorflow.keras 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iyNYIYOG7Rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "ba8a0267-e2b9-49e4-c6a7-ec1c054d35c0"
      },
      "source": [
        "# tfrecord 文件格式\n",
        "# tfrecord其实是一个文件格式\n",
        "# 它里面存储的内容呢，都是tf.trian.Example,这个Example呢可以是一个样本，也可以是一组样本\n",
        "# 对于每一个example它里面是什么呢\n",
        "# ---》里面都是一个一个的tf.train.Features.而对于Features呢，你可以把他理解成dict.在dict里面，\n",
        "#   key就是你定义的feature的名字，value就是具体的值\n",
        "#   而对于每个不同的tf.train.Features呢，他都有不同的格式，分别有tf.train.ByteList（存储字符串）/FloatList（存储float）/Int64List(存储整数)\n",
        "#   这是tf.record的一个内容，他是一个层层往下分的过程\n",
        "#   他把每个样本呢，都抽象成一系列的features,然后这些features组成一个example,把具体的example呢，按照某种方式存储到tf.record文件当中去，\n",
        "#   就得到了tf.record的一个文件\n",
        "\n",
        "# -> tf.train.Example\n",
        "#    -> tf.train.Features -> {\"key\": tf.train.Feature}\n",
        "#       -> tf.train.Feature -> tf.train.ByteList/FloatList/Int64List\n",
        "\n",
        "#先看tf.train.ByteList/FloatList/Int64List，再看tf.train.Features，再看tf.train.Example，最后是tfrecord\n",
        "favorite_books = [name.encode('utf-8')\n",
        "                  for name in [\"machine learning\", \"cc150\"]] #需要把字符串转成utf8的格式，这里需要做一个转换\n",
        "                  # 这样就得到要给utf8的列表\n",
        "favorite_books_bytelist = tf.train.BytesList(value = favorite_books) # 再把这个列表传给tf.train.BytesList,来获得一个ByteList的对象，传的参数名字呢是value\n",
        "print(favorite_books_bytelist)\n",
        "\n",
        "hours_floatlist = tf.train.FloatList(value = [15.5, 9.5, 7.0, 8.0]) #同样的方法去初始化一个FloatList\n",
        "print(hours_floatlist)\n",
        "\n",
        "age_int64list = tf.train.Int64List(value = [42]) #同样的方法去初始化一个Int64List\n",
        "print(age_int64list)\n",
        "\n",
        "features = tf.train.Features( #在有了favorite_books hours_floatlist age_int64list以后我们就可以去创建features对象了\n",
        "    # 我们使用tf.train.Features去构建featrues对象                        \n",
        "    feature = { # 这里面需要传进去的是一个叫feature的参数，feature参数是一个dict\n",
        "        \"favorite_books\": tf.train.Feature( #用favorite_books_bytelist去初始化一个tf.train.Feature对象\n",
        "            bytes_list = favorite_books_bytelist),\n",
        "        \"hours\": tf.train.Feature(\n",
        "            float_list = hours_floatlist),\n",
        "        \"age\": tf.train.Feature(int64_list = age_int64list),\n",
        "    }\n",
        ")\n",
        "print(features) #打印features"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value: \"machine learning\"\n",
            "value: \"cc150\"\n",
            "\n",
            "value: 15.5\n",
            "value: 9.5\n",
            "value: 7.0\n",
            "value: 8.0\n",
            "\n",
            "value: 42\n",
            "\n",
            "feature {\n",
            "  key: \"age\"\n",
            "  value {\n",
            "    int64_list {\n",
            "      value: 42\n",
            "    }\n",
            "  }\n",
            "}\n",
            "feature {\n",
            "  key: \"favorite_books\"\n",
            "  value {\n",
            "    bytes_list {\n",
            "      value: \"machine learning\"\n",
            "      value: \"cc150\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "feature {\n",
            "  key: \"hours\"\n",
            "  value {\n",
            "    float_list {\n",
            "      value: 15.5\n",
            "      value: 9.5\n",
            "      value: 7.0\n",
            "      value: 8.0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpWdlmePG7Rv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "36a57207-2c7e-4bc1-eef5-98980555babc"
      },
      "source": [
        "example = tf.train.Example(features=features) #有了features 就可以组建一个example了\n",
        "print(example)\n",
        "\n",
        "serialized_example = example.SerializeToString() #可以把example序列化，因为存储的时候需要对内容进行一个压缩，以减少它的size\n",
        "print(serialized_example)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features {\n",
            "  feature {\n",
            "    key: \"age\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 42\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"favorite_books\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"machine learning\"\n",
            "        value: \"cc150\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"hours\"\n",
            "    value {\n",
            "      float_list {\n",
            "        value: 15.5\n",
            "        value: 9.5\n",
            "        value: 7.0\n",
            "        value: 8.0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "b'\\n\\\\\\n\\x1d\\n\\x05hours\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xe0@\\x00\\x00\\x00A\\n-\\n\\x0efavorite_books\\x12\\x1b\\n\\x19\\n\\x10machine learning\\n\\x05cc150\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yRA5_d-G7Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#如何把example存到文件当中去，生成一个具体的tfrecord的文件\n",
        "output_dir = 'tfrecord_basic'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir) \n",
        "filename = \"test.tfrecords\"\n",
        "filename_fullpath = os.path.join(output_dir, filename) #全路径\n",
        "with tf.io.TFRecordWriter(filename_fullpath) as writer: #用tf.io.TFRecordWriter打开了一个tfrecord文件\n",
        "    for i in range(3):\n",
        "        writer.write(serialized_example) # 把刚才定义好的example写进去三次\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ZyVwsBG7R0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "7e558cb3-9da5-4b07-e4c6-07c4afddd025"
      },
      "source": [
        "#如何读取tfrecord文件呢\n",
        "dataset = tf.data.TFRecordDataset([filename_fullpath])#传进去的是一个列表，是我们刚才定义的全路径，文件中写的都是序列化好的example，所以读出来\n",
        "for serialized_example_tensor in dataset:\n",
        "    print(serialized_example_tensor) #所以读出来的都是一堆字符串"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'\\n\\\\\\n\\x1d\\n\\x05hours\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xe0@\\x00\\x00\\x00A\\n-\\n\\x0efavorite_books\\x12\\x1b\\n\\x19\\n\\x10machine learning\\n\\x05cc150\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\n\\\\\\n\\x1d\\n\\x05hours\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xe0@\\x00\\x00\\x00A\\n-\\n\\x0efavorite_books\\x12\\x1b\\n\\x19\\n\\x10machine learning\\n\\x05cc150\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\n\\\\\\n\\x1d\\n\\x05hours\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xe0@\\x00\\x00\\x00A\\n-\\n\\x0efavorite_books\\x12\\x1b\\n\\x19\\n\\x10machine learning\\n\\x05cc150\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35fVvWiYG7R3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1723e04a-4bf7-4c89-ed0f-dc0f830061e7"
      },
      "source": [
        "#如何把序列化后example解析成正常的肉眼可以识别的的example呢\n",
        "#需要首先定义一个字典，字典中定义了每个feature及其所对应的类型\n",
        "#这里有三个特征favorite_books hours age\n",
        "expected_features = {\n",
        "    \"favorite_books\": tf.io.VarLenFeature(dtype = tf.string), #类型是tf.io.VarLenFeature是一个变长的feature,具体的类型是字符串\n",
        "    \"hours\": tf.io.VarLenFeature(dtype = tf.float32), #变长的feature,因为他是一个列表，他的类型是tf.float32\n",
        "    \"age\": tf.io.FixedLenFeature([], dtype = tf.int64), #age是一个定长的类型，因为他只有一个元素，tf.io.FixedLenFeature，它的type是tf.int64\n",
        "}#这样我们就定义好了我们features中三个数值的具体类型\n",
        "\n",
        "dataset = tf.data.TFRecordDataset([filename_fullpath]) \n",
        "for serialized_example_tensor in dataset:\n",
        "    #print(serialized_example_tensor) 读出来的都是一堆字符串，这里不再直接打印了，而是解析一下\n",
        "    example = tf.io.parse_single_example( #调用的是tf.io.parse_single_example\n",
        "        serialized_example_tensor,#具体的序列化后的tensor\n",
        "        expected_features)    #期待的一个类型\n",
        "    print(\"example=\" , example)\n",
        "    print(\"age=\",example[\"age\"])  \n",
        "    print(\"favorite_books=\",example[\"favorite_books\"])      \n",
        "    books = tf.sparse.to_dense(example[\"favorite_books\"], #\n",
        "                               default_value=b\"\") #不能把0当初默认值传成字符串，这里就把default_value改成一个默认字符串\n",
        "    print(\"books=\", books)\n",
        "    for book in books:\n",
        "        print(book.numpy().decode(\"UTF-8\")) #之前做了encode 这里做一个decode"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example= {'favorite_books': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04b710>, 'hours': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04b5c0>, 'age': <tf.Tensor: shape=(), dtype=int64, numpy=42>}\n",
            "age= tf.Tensor(42, shape=(), dtype=int64)\n",
            "favorite_books= SparseTensor(indices=tf.Tensor(\n",
            "[[0]\n",
            " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64))\n",
            "books= tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string)\n",
            "machine learning\n",
            "cc150\n",
            "example= {'favorite_books': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04bf28>, 'hours': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04b4e0>, 'age': <tf.Tensor: shape=(), dtype=int64, numpy=42>}\n",
            "age= tf.Tensor(42, shape=(), dtype=int64)\n",
            "favorite_books= SparseTensor(indices=tf.Tensor(\n",
            "[[0]\n",
            " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64))\n",
            "books= tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string)\n",
            "machine learning\n",
            "cc150\n",
            "example= {'favorite_books': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04b0b8>, 'hours': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f139a04b5c0>, 'age': <tf.Tensor: shape=(), dtype=int64, numpy=42>}\n",
            "age= tf.Tensor(42, shape=(), dtype=int64)\n",
            "favorite_books= SparseTensor(indices=tf.Tensor(\n",
            "[[0]\n",
            " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64))\n",
            "books= tf.Tensor([b'machine learning' b'cc150'], shape=(2,), dtype=string)\n",
            "machine learning\n",
            "cc150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eVWtxXKG7R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#除了正常存储 还可以把tfrecord存成压缩文件\n",
        "filename_fullpath_zip = filename_fullpath + '.zip' #首先定义一个文件名，就是在正常文件后面加上.zip就可以了\n",
        "options = tf.io.TFRecordOptions(compression_type = \"GZIP\") #我们如果想把文存成压缩形式，需要定义一个options，\n",
        "#在compression_type里面定义一个compression_type，这里使用GZIP\n",
        "#有了option以后再打开文件的时候，需要把option传进去，然后在进行存储\n",
        "with tf.io.TFRecordWriter(filename_fullpath_zip, options) as writer:\n",
        "    for i in range(3):\n",
        "        writer.write(serialized_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q17iDJVAG7R9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "803e05e8-a617-4e19-d279-d266fbd76663"
      },
      "source": [
        "#对于压缩后的文件，该如何读取呢\n",
        "#读取的方法也很类似，在读取的时候，我们在创建dataset的时候，把这个compression_type也要传进去，这里他就等于GZIP\n",
        "#其他部分不变\n",
        "dataset_zip = tf.data.TFRecordDataset([filename_fullpath_zip],  compression_type= \"GZIP\")\n",
        "for serialized_example_tensor in dataset_zip:\n",
        "    example = tf.io.parse_single_example(\n",
        "        serialized_example_tensor,\n",
        "        expected_features)\n",
        "    books = tf.sparse.to_dense(example[\"favorite_books\"],\n",
        "                               default_value=b\"\")\n",
        "    for book in books:\n",
        "        print(book.numpy().decode(\"UTF-8\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "machine learning\n",
            "cc150\n",
            "machine learning\n",
            "cc150\n",
            "machine learning\n",
            "cc150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbXgBOJXG7R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}