{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tf1_customized_estimator.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingmingbupt/tensorflow/blob/master/tf1_customized_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUn3C4_aqONx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "627cffa7-989d-4fc7-a854-5d6f025513da"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "1.15.2\n",
            "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.1\n",
            "numpy 1.18.2\n",
            "pandas 1.0.3\n",
            "sklearn 0.22.2.post1\n",
            "tensorflow 1.15.2\n",
            "tensorflow.python.keras.api._v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351qoG2ZrxtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "bc0e188a-2032-4a55-b0de-44c9b6edc98a"
      },
      "source": [
        "#如何在colab上使用在google cloud上面的文件\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#path = \"/content/drive/My Drive/Colab Notebooks/tensorflow/Tensorflow2.0--rumendaoshijian/chapter_5_tf1\"\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/tensorflow/Tensorflow2.0--rumendaoshijian/chapter_5_tf1（带数据）\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf1_customized_estimator.ipynb',\n",
              " 'data',\n",
              " 'tf1_dense_network.ipynb',\n",
              " 'tf1_dataset.ipynb',\n",
              " 'tf1_initialized_dataset.ipynb',\n",
              " 'customized_estimator']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atcC-_7iqON2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "64f0ecb1-566f-4a84-e2cc-cf672c00ee82"
      },
      "source": [
        "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
        "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
        "train_file = \"./data/titanic/train.csv\"\n",
        "eval_file = \"./data/titanic/eval.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "eval_df = pd.read_csv(eval_file)\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  22.0  ...  unknown  Southampton      n\n",
            "1         1  female  38.0  ...        C    Cherbourg      n\n",
            "2         1  female  26.0  ...  unknown  Southampton      y\n",
            "3         1  female  35.0  ...        C  Southampton      n\n",
            "4         0    male  28.0  ...  unknown   Queenstown      y\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  35.0  ...  unknown  Southampton      y\n",
            "1         0    male  54.0  ...        E  Southampton      y\n",
            "2         1  female  58.0  ...        C  Southampton      y\n",
            "3         1  female  55.0  ...  unknown  Southampton      y\n",
            "4         1    male  34.0  ...        D  Southampton      y\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR2smicEqON5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "f9b9158f-b7bb-456a-d2e1-02970a84e55e"
      },
      "source": [
        "y_train = train_df.pop('survived')\n",
        "y_eval = eval_df.pop('survived')\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())\n",
        "print(y_train.head())\n",
        "print(y_eval.head())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      sex   age  n_siblings_spouses  parch  ...  class     deck  embark_town alone\n",
            "0    male  22.0                   1      0  ...  Third  unknown  Southampton     n\n",
            "1  female  38.0                   1      0  ...  First        C    Cherbourg     n\n",
            "2  female  26.0                   0      0  ...  Third  unknown  Southampton     y\n",
            "3  female  35.0                   1      0  ...  First        C  Southampton     n\n",
            "4    male  28.0                   0      0  ...  Third  unknown   Queenstown     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "      sex   age  n_siblings_spouses  parch  ...   class     deck  embark_town alone\n",
            "0    male  35.0                   0      0  ...   Third  unknown  Southampton     y\n",
            "1    male  54.0                   0      0  ...   First        E  Southampton     y\n",
            "2  female  58.0                   0      0  ...   First        C  Southampton     y\n",
            "3  female  55.0                   0      0  ...  Second  unknown  Southampton     y\n",
            "4    male  34.0                   0      0  ...  Second        D  Southampton     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqqKnwtIqON7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "0c8e237d-d4c9-4603-c884-c29ce70c7489"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydAIYOTqON-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "55d2a6b2-6da2-48d0-fb7f-9e5f60f40aeb"
      },
      "source": [
        "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "numeric_columns = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique()\n",
        "    print(categorical_column, vocab)\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.indicator_column(\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "                categorical_column, vocab)))\n",
        "\n",
        "for categorical_column in numeric_columns:\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.numeric_column(\n",
        "            categorical_column, dtype=tf.float32))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male' 'female']\n",
            "n_siblings_spouses [1 0 3 4 2 5 8]\n",
            "parch [0 1 2 5 3 4]\n",
            "class ['Third' 'First' 'Second']\n",
            "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
            "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
            "alone ['n' 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZIT40EqOOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
        "                 batch_size = 32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next() \n",
        "    #在tensorflow1.0里面，dataset需要调用iterator,然后调用get_next，来获取具体值的tensor，返回的值就可以在自定义的model_fn里直接使用了"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj8YdHjqqOOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "904ae688-e098-45f7-e5b9-82740f827e71"
      },
      "source": [
        "output_dir = \"customized_estimator\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "def model_fn(features, labels, mode, params): #定义函数，四个参数\n",
        "    # model 就是运行时状态runtime state: Train, Eval, Predict（线上服务预测的时候）\n",
        "    # train和eval的时候是可以得到准确率和loss，但是在predict的时候是得不到的\n",
        "    # 在model不同的时候，得到不同的返回值\n",
        "    input_for_next_layer = tf.feature_column.input_layer( # tf.feature_column.input_layer他和keras.layers.denseFeatures是一样的作用\n",
        "    #他会把我们的features给解析出来，利用的就是params['feature_columns']参数\n",
        "        features, params['feature_columns']) # 第一层，把features解析出来\n",
        "    for n_unit in params['hidden_units']: #隐含层，使用循环来构建全连接层\n",
        "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                               units = n_unit,\n",
        "                                               activation = tf.nn.relu)\n",
        "    logits = tf.layers.dense(input_for_next_layer,\n",
        "                             params['n_classes'],\n",
        "                             activation = None) #无激活函数\n",
        "    predicted_classes = tf.argmax(logits, 1)  #获得我们预测出来的类\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT: #predict\n",
        "       #给predict mode返回结果，predictions是一个字典\n",
        "        predictions = {\n",
        "            \"class_ids\": predicted_classes[:, tf.newaxis], \n",
        "            #要求返回的是一个 (n * 1)的一个矩阵，这里predicted_classes是一个长度为n的向量，所以我要给他扩展一个维度\n",
        "            \"probabilities\": tf.nn.softmax(logits), #也就是他输出的概率分布，可以通过给logits做softmax获得\n",
        "            \"logits\": logits\n",
        "        }#这样就构建好了我们的字典\n",
        "        #对于自定义的estimator来说，他的自定义的model_fn都必须返回的是一个tf.estimator.EstimatorSpec的对象\n",
        "        #这个estimator就定义了session run要run那些op,这里就是在predictions里面的参数，class_ids，probabilities，logits\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions = predictions)\n",
        "    \n",
        "    #计算我们的损失函数，使用sparse_softmax_cross_entropy来进行计算\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
        "    #计算准确率。之前的例子里我们使用了比较原始的方法来计算准确率。就是想让predicted_classes和labels之间对比，在对比的结果上呢，\n",
        "    #我们去取平均，得到准确率。在这里我们使用一个高层的封装，tf.metrics.accuracy，这个封装的好处就是他可以帮我们计算累计的准确率\n",
        "    #在之前的例子中eval的时候，我们是在不同batch上分别求准确率，然后再去求平均。然而在 tf.metrics.accuracy这里呢，就不需要了\n",
        "    #因为我的这个tf.metrics.accuracy可以帮我去做累计\n",
        "    accuracy = tf.metrics.accuracy(labels = labels, predictions = predicted_classes, name = \"acc_op\")\n",
        "    metrics = {\"accuracy\": accuracy} #定义了我们的指标\n",
        "    if mode == tf.estimator.ModeKeys.EVAL: #eval\n",
        "        return tf.estimator.EstimatorSpec(mode, loss = loss,eval_metric_ops = metrics)\n",
        "    #eval mode下返回的依然是tf.estimator.EstimatorSpec，有三个参数，mode,loss,eval_metric_ops\n",
        "    #train mode                                   \n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
        "    #train mode下需要参数mode loss train_op\n",
        "    return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = train_op)\n",
        "\n",
        "#用定义好的函数去初始化我们的estimator，用自定义的函数去初始化estimator也非常简单\n",
        "#需要调用tf.estimator.Estimator， 第一个是model_fn,就是我们上面定义的model_fn\n",
        "#model_dir\n",
        "#params是个字典，通过model_fn(features, labels, mode, params)里面的params传到model_fn当中来\n",
        "#这样就可以构建一个自定义的estimator了\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn = model_fn,\n",
        "    model_dir = output_dir,\n",
        "    params = {\n",
        "        \"feature_columns\": feature_columns, #之前的feature_columns传进去\n",
        "        \"hidden_units\": [100, 100],#神经网络的层次，单元数\n",
        "        \"n_classes\": 2 #类别数2类\n",
        "    })\n",
        "\n",
        "#model_fn完成了 和 estimator初始化好了\n",
        "estimator.train(input_fn = lambda : make_dataset(\n",
        "    train_df, y_train, epochs = 100))#参数只有input_fn"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8d30683f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From <ipython-input-20-aba61547e2e9>:8: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:206: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:207: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:206: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:2158: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4300: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column.py:2158: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4271: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4326: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From <ipython-input-21-4a7c60aac522>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.86279464, step = 1\n",
            "INFO:tensorflow:global_step/sec: 344.286\n",
            "INFO:tensorflow:loss = 0.5022012, step = 101 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.379\n",
            "INFO:tensorflow:loss = 0.26197794, step = 201 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.038\n",
            "INFO:tensorflow:loss = 0.33399346, step = 301 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.591\n",
            "INFO:tensorflow:loss = 0.43572485, step = 401 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.564\n",
            "INFO:tensorflow:loss = 0.30999327, step = 501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.198\n",
            "INFO:tensorflow:loss = 0.4209226, step = 601 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.277\n",
            "INFO:tensorflow:loss = 0.27656975, step = 701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.379\n",
            "INFO:tensorflow:loss = 0.2189718, step = 801 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.11\n",
            "INFO:tensorflow:loss = 0.36905426, step = 901 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.702\n",
            "INFO:tensorflow:loss = 0.33821452, step = 1001 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.193\n",
            "INFO:tensorflow:loss = 0.32185048, step = 1101 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.866\n",
            "INFO:tensorflow:loss = 0.18772703, step = 1201 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.122\n",
            "INFO:tensorflow:loss = 0.30412364, step = 1301 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.159\n",
            "INFO:tensorflow:loss = 0.32800668, step = 1401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.252\n",
            "INFO:tensorflow:loss = 0.3255874, step = 1501 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.38\n",
            "INFO:tensorflow:loss = 0.1714912, step = 1601 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.046\n",
            "INFO:tensorflow:loss = 0.3598823, step = 1701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.017\n",
            "INFO:tensorflow:loss = 0.32196608, step = 1801 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.411\n",
            "INFO:tensorflow:loss = 0.42100757, step = 1901 (0.191 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.3317304.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f8cf7131d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWecpobXqOOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d207566d-52b6-49ca-a288-c4876967da04"
      },
      "source": [
        "estimator.evaluate(lambda : make_dataset(\n",
        "    eval_df, y_eval, epochs = 1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-06T07:02:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-1960\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-06-07:02:11\n",
            "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7916667, global_step = 1960, loss = 0.4775967\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator/model.ckpt-1960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7916667, 'global_step': 1960, 'loss': 0.4775967}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThpXovU-qOOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}